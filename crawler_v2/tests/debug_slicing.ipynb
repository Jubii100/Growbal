{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from typing import Dict, Any, List, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "# Debug helpers (updated for tests/ subdirectory)\n",
        "BASE_DIR = Path(__file__).parent.parent if \"__file__\" in globals() else Path(\"..\").resolve()\n",
        "LOG_DIR = BASE_DIR / \"logs\"\n",
        "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    import ollama\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"The 'ollama' Python package is required. Install it and ensure Ollama is running.\")\n",
        "\n",
        "\n",
        "def read_text_file(path: str | Path) -> str:\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {p}\")\n",
        "    return p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "\n",
        "def approx_token_count(text: str) -> int:\n",
        "    # Rough token proxy for debugging\n",
        "    return len(re.findall(r\"\\S+\", text))\n",
        "\n",
        "\n",
        "def build_tool_schema() -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_slices\",\n",
        "            \"description\": \"Return slice ranges to extract relevant HTML lines.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"slices\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"first_line\": {\"type\": \"integer\"},\n",
        "                                \"last_line\": {\"type\": \"integer\"}\n",
        "                            },\n",
        "                            \"required\": [\"first_line\", \"last_line\"]\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"slices\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_tool_args(resp: Any) -> Dict[str, Any]:\n",
        "    # Supports dict or object-shaped response\n",
        "    if isinstance(resp, dict):\n",
        "        tcs = (resp.get(\"message\", {}) or {}).get(\"tool_calls\", [])\n",
        "        if tcs:\n",
        "            fn = tcs[0].get(\"function\", {})\n",
        "            raw = fn.get(\"arguments\")\n",
        "            if isinstance(raw, str):\n",
        "                try:\n",
        "                    return json.loads(raw)\n",
        "                except Exception:\n",
        "                    return {}\n",
        "            if isinstance(raw, dict):\n",
        "                return raw\n",
        "        return {}\n",
        "    # object style\n",
        "    message = getattr(resp, \"message\", None)\n",
        "    if message is None:\n",
        "        return {}\n",
        "    tcs = getattr(message, \"tool_calls\", []) or []\n",
        "    if not tcs:\n",
        "        return {}\n",
        "    fn = getattr(tcs[0], \"function\", None)\n",
        "    if fn is None:\n",
        "        return {}\n",
        "    raw = getattr(fn, \"arguments\", None)\n",
        "    if isinstance(raw, str):\n",
        "        try:\n",
        "            return json.loads(raw)\n",
        "        except Exception:\n",
        "            return {}\n",
        "    if isinstance(raw, dict):\n",
        "        return raw\n",
        "    return {}\n",
        "\n",
        "\n",
        "def get_slices_from_args(args: Dict[str, Any]) -> List[Tuple[int, int]]:\n",
        "    out: List[Tuple[int, int]] = []\n",
        "    for sl in (args.get(\"slices\") or []):\n",
        "        a = None\n",
        "        b = None\n",
        "        if isinstance(sl, dict):\n",
        "            # Accept multiple key variants\n",
        "            a = (\n",
        "                sl.get(\"first_line\")\n",
        "                if sl.get(\"first_line\") is not None else sl.get(\"start\")\n",
        "                if sl.get(\"start\") is not None else sl.get(\"from\")\n",
        "            )\n",
        "            b = (\n",
        "                sl.get(\"last_line\")\n",
        "                if sl.get(\"last_line\") is not None else sl.get(\"end\")\n",
        "                if sl.get(\"end\") is not None else sl.get(\"to\")\n",
        "            )\n",
        "        elif isinstance(sl, list) and len(sl) >= 2:\n",
        "            a, b = sl[0], sl[1]\n",
        "        try:\n",
        "            a = int(a)\n",
        "            b = int(b)\n",
        "        except Exception:\n",
        "            continue\n",
        "        a = max(0, a)\n",
        "        b = max(a, b)\n",
        "        out.append((a, b))\n",
        "    return out\n",
        "\n",
        "\n",
        "def apply_slices(html_text: str, slices: List[Tuple[int, int]]) -> str:\n",
        "    if not slices:\n",
        "        return \"\"\n",
        "    lines = html_text.splitlines()\n",
        "    chunks: List[str] = []\n",
        "    for a, b in slices:\n",
        "        a = max(0, a)\n",
        "        b = min(len(lines) - 1, b)\n",
        "        if a <= b:\n",
        "            chunks.append(\"\\n\".join(lines[a:b+1]))\n",
        "    return \"\\n\\n\".join(chunks)\n",
        "\n",
        "\n",
        "def focus_html(html_text: str, keyword_window: int = 3) -> str:\n",
        "    # Extract lines around likely-interesting keywords\n",
        "    key_re = re.compile(r\"about|service|contact|team|clients|email|phone|address|location|office|company|who\\s+we|vision\", re.I)\n",
        "    lines = html_text.splitlines()\n",
        "    keep = set()\n",
        "    for idx, ln in enumerate(lines):\n",
        "        if key_re.search(ln):\n",
        "            for j in range(max(0, idx - keyword_window), min(len(lines), idx + keyword_window + 1)):\n",
        "                keep.add(j)\n",
        "    # Always keep header/footer windows\n",
        "    for j in range(min(200, len(lines))):\n",
        "        keep.add(j)\n",
        "    for j in range(max(0, len(lines) - 200), len(lines)):\n",
        "        keep.add(j)\n",
        "    focused = \"\\n\".join(lines[i] for i in sorted(keep))\n",
        "    return focused\n",
        "\n",
        "\n",
        "def _normalize_ollama_resp(resp: Any) -> Dict[str, Any]:\n",
        "    \"\"\"Return a minimal JSON-serializable dict with content and tool_calls.\"\"\"\n",
        "    out: Dict[str, Any] = {\"content\": None, \"thinking\": None, \"tool_calls\": []}\n",
        "    if isinstance(resp, dict):\n",
        "        msg = resp.get(\"message\") or {}\n",
        "        out[\"content\"] = msg.get(\"content\")\n",
        "        out[\"thinking\"] = msg.get(\"thinking\")\n",
        "        for tc in (msg.get(\"tool_calls\") or []):\n",
        "            fn = tc.get(\"function\") or {}\n",
        "            out[\"tool_calls\"].append({\n",
        "                \"name\": fn.get(\"name\"),\n",
        "                \"arguments\": fn.get(\"arguments\"),\n",
        "            })\n",
        "        return out\n",
        "    # object style\n",
        "    message = getattr(resp, \"message\", None)\n",
        "    if message is not None:\n",
        "        out[\"content\"] = getattr(message, \"content\", None)\n",
        "        out[\"thinking\"] = getattr(message, \"thinking\", None)\n",
        "        tcs = getattr(message, \"tool_calls\", []) or []\n",
        "        norm_tcs: List[Dict[str, Any]] = []\n",
        "        for tc in tcs:\n",
        "            fn = getattr(tc, \"function\", None)\n",
        "            name = getattr(fn, \"name\", None) if fn is not None else None\n",
        "            args = getattr(fn, \"arguments\", None) if fn is not None else None\n",
        "            norm_tcs.append({\"name\": name, \"arguments\": args})\n",
        "        out[\"tool_calls\"] = norm_tcs\n",
        "    return out\n",
        "\n",
        "\n",
        "def run_ollama_slicing(html_text: str, model: str = \"gpt-oss:20b\", num_ctx: int = 8192, temperature: float = 0.0,\n",
        "                        save_prefix: str = \"debug\") -> Dict[str, Any]:\n",
        "    client = ollama.Client(host=os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\"))\n",
        "\n",
        "    # Try to fetch model metadata\n",
        "    try:\n",
        "        model_info = client.show(model)\n",
        "    except Exception:\n",
        "        model_info = None\n",
        "\n",
        "    tools = [build_tool_schema()]\n",
        "    prompt = html_text\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            \"Respond ONLY by calling the get_slices function with arguments that EXACTLY match the provided JSON Schema. \"\n",
        "            \"Return 3-12 concise, non-overlapping ranges that capture ABOUT/WHO WE ARE, SERVICES, CONTACT (emails/phones/addresses), \"\n",
        "            \"and any TEAM/CLIENTS sections. Use line indices of the provided HTML text.\"\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    # Save prompt for inspection\n",
        "    (LOG_DIR / f\"{save_prefix}_prompt.txt\").write_text(prompt, encoding=\"utf-8\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    resp = client.chat(model=model, messages=messages, tools=tools, options={\"temperature\": temperature, \"num_ctx\": num_ctx})\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    # Save raw response (string repr)\n",
        "    try:\n",
        "        raw = json.dumps(resp, ensure_ascii=False, indent=2)\n",
        "    except Exception:\n",
        "        raw = str(resp)\n",
        "    (LOG_DIR / f\"{save_prefix}_response.json\").write_text(raw, encoding=\"utf-8\")\n",
        "\n",
        "    # Save normalized JSON for easy inspection\n",
        "    norm = _normalize_ollama_resp(resp)\n",
        "    (LOG_DIR / f\"{save_prefix}_normalized.json\").write_text(json.dumps(norm, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "    args = extract_tool_args(resp)\n",
        "    slices = get_slices_from_args(args)\n",
        "    sliced_html = apply_slices(html_text, slices)\n",
        "    (LOG_DIR / f\"{save_prefix}_sliced_html.txt\").write_text(sliced_html, encoding=\"utf-8\")\n",
        "\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"model_info\": model_info,\n",
        "        \"elapsed_sec\": dt,\n",
        "        \"num_ctx\": num_ctx,\n",
        "        \"temperature\": temperature,\n",
        "        \"token_est_input\": approx_token_count(html_text),\n",
        "        \"num_lines_input\": len(html_text.splitlines()),\n",
        "        \"num_slices\": len(slices),\n",
        "        \"slices\": slices,\n",
        "        \"sliced_len\": len(sliced_html)\n",
        "    }\n",
        "\n",
        "\n",
        "def debug_slicing(html_path: str | Path,\n",
        "                  model: str = \"gpt-oss:20b\",\n",
        "                  num_ctx: int = 8192,\n",
        "                  temperature: float = 0.0,\n",
        "                  fallback_focus: bool = True,\n",
        "                  save_prefix: str = \"debug\") -> Dict[str, Any]:\n",
        "    html_text = read_text_file(html_path)\n",
        "\n",
        "    print(f\"Loaded {html_path}\")\n",
        "    print(f\"Chars: {len(html_text):,}  |  Lines: {len(html_text.splitlines()):,}  |  ~Tokens: {approx_token_count(html_text):,}\")\n",
        "\n",
        "    result = run_ollama_slicing(html_text, model=model, num_ctx=num_ctx, temperature=temperature, save_prefix=save_prefix)\n",
        "    print(json.dumps({k: v for k, v in result.items() if k not in (\"model_info\", \"slices\")}, indent=2))\n",
        "\n",
        "    if result[\"num_slices\"] == 0 and fallback_focus:\n",
        "        print(\"No slices from full input. Retrying with focused HTML window...\")\n",
        "        focused = focus_html(html_text)\n",
        "        (LOG_DIR / f\"{save_prefix}_focused_input.txt\").write_text(focused, encoding=\"utf-8\")\n",
        "        focus_res = run_ollama_slicing(focused, model=model, num_ctx=num_ctx, temperature=temperature, save_prefix=f\"{save_prefix}_focus\")\n",
        "        print(json.dumps({k: v for k, v in focus_res.items() if k not in (\"model_info\", \"slices\")}, indent=2))\n",
        "        result[\"focus_attempt\"] = focus_res\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded /home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing_additional.txt\n",
            "Chars: 32,577  |  Lines: 406  |  ~Tokens: 2,038\n",
            "{\n",
            "  \"model\": \"gpt-oss:20b\",\n",
            "  \"elapsed_sec\": 46.80624198913574,\n",
            "  \"num_ctx\": 16384,\n",
            "  \"temperature\": 0.0,\n",
            "  \"token_est_input\": 2038,\n",
            "  \"num_lines_input\": 406,\n",
            "  \"num_slices\": 4,\n",
            "  \"sliced_len\": 32563\n",
            "}\n",
            "\n",
            "Summary:\n",
            "{\n",
            "  \"model\": \"gpt-oss:20b\",\n",
            "  \"elapsed_sec\": 46.80624198913574,\n",
            "  \"num_ctx\": 16384,\n",
            "  \"temperature\": 0.0,\n",
            "  \"token_est_input\": 2038,\n",
            "  \"num_lines_input\": 406,\n",
            "  \"num_slices\": 4,\n",
            "  \"sliced_len\": 32563\n",
            "}\n",
            "Slices: [(1, 200), (201, 400), (401, 600), (601, 800)]\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/home/mohammed/Desktop/tech_projects/growbal/envs/1.env\", override=True)\n",
        "\n",
        "html_file = \"/home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing_additional.txt\"\n",
        "if not os.path.exists(html_file) or os.path.getsize(html_file) == 0:\n",
        "    html_file = \"/home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing.txt\"\n",
        "\n",
        "res = debug_slicing(html_file, model=\"gpt-oss:20b\", num_ctx=16384, temperature=0.0, fallback_focus=True, save_prefix=\"slicing_debug\")\n",
        "print(\"\\nSummary:\")\n",
        "print(json.dumps({k: v for k, v in res.items() if k not in (\"model_info\", \"slices\", \"focus_attempt\")}, indent=2))\n",
        "print(\"Slices:\", res.get(\"slices\"))\n",
        "if res.get(\"focus_attempt\"):\n",
        "    print(\"\\nFocus attempt summary:\")\n",
        "    print(json.dumps({k: v for k, v in res[\"focus_attempt\"].items() if k not in (\"model_info\", \"slices\")}, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_last_response(prefix: str = \"slicing_debug\") -> None:\n",
        "    path = LOG_DIR / f\"{prefix}_response.json\"\n",
        "    if not path.exists():\n",
        "        print(f\"No response file at {path}\")\n",
        "        return\n",
        "    try:\n",
        "        data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        print(\"Response file is not valid JSON; raw content below:\\n\")\n",
        "        print(path.read_text(encoding=\"utf-8\"))\n",
        "        return\n",
        "    msg = (data.get(\"message\") or {})\n",
        "    tc = msg.get(\"tool_calls\")\n",
        "    print(\"Has tool_calls:\", bool(tc))\n",
        "    if tc:\n",
        "        print(json.dumps(tc, ensure_ascii=False, indent=2)[:2000])\n",
        "    else:\n",
        "        print(\"Assistant content:\\n\")\n",
        "        print((msg.get(\"content\") or \"\")[:2000])\n",
        "\n",
        "\n",
        "def run_json_slicing(html_text: str, model: str = \"gpt-oss:20b\", num_ctx: int = 16384,\n",
        "                     temperature: float = 0.0, save_prefix: str = \"slicing_debug_json\") -> Dict[str, Any]:\n",
        "    \"\"\"Ask the model to output ONLY JSON with slices (no tools).\"\"\"\n",
        "    client = ollama.Client(host=os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\"))\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You will receive an HTML text split by lines. \"\n",
        "        \"Return ONLY a JSON object of the form: {\\\"slices\\\":[{\\\"first_line\\\":int,\\\"last_line\\\":int}, ...]}. \"\n",
        "        \"Choose 3-12 non-overlapping ranges that capture ABOUT/WHO WE ARE, SERVICES, CONTACT (emails/phones/addresses), and TEAM/CLIENTS sections. \"\n",
        "        \"Use 0-based line indices relative to the provided text. Do not include any other keys or text.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": html_text}\n",
        "    ]\n",
        "\n",
        "    (LOG_DIR / f\"{save_prefix}_prompt.txt\").write_text(html_text, encoding=\"utf-8\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    # Force JSON output format\n",
        "    resp = client.chat(model=model, messages=messages, options={\"temperature\": temperature, \"num_ctx\": num_ctx, \"format\": \"json\"})\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    try:\n",
        "        raw = json.dumps(resp, ensure_ascii=False, indent=2)\n",
        "    except Exception:\n",
        "        raw = str(resp)\n",
        "    (LOG_DIR / f\"{save_prefix}_response.json\").write_text(raw, encoding=\"utf-8\")\n",
        "\n",
        "    # Parse JSON content\n",
        "    content = None\n",
        "    if isinstance(resp, dict):\n",
        "        content = (resp.get(\"message\") or {}).get(\"content\")\n",
        "    if not content:\n",
        "        content = raw\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(content)\n",
        "    except Exception:\n",
        "        parsed = {}\n",
        "\n",
        "    slices = get_slices_from_args(parsed)\n",
        "    sliced_html = apply_slices(html_text, slices)\n",
        "    (LOG_DIR / f\"{save_prefix}_sliced_html.txt\").write_text(sliced_html, encoding=\"utf-8\")\n",
        "\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"elapsed_sec\": dt,\n",
        "        \"num_ctx\": num_ctx,\n",
        "        \"temperature\": temperature,\n",
        "        \"token_est_input\": approx_token_count(html_text),\n",
        "        \"num_lines_input\": len(html_text.splitlines()),\n",
        "        \"num_slices\": len(slices),\n",
        "        \"slices\": slices,\n",
        "        \"sliced_len\": len(sliced_html)\n",
        "    }\n",
        "\n",
        "\n",
        "def rule_based_slicing(html_text: str, window: int = 8) -> Dict[str, Any]:\n",
        "    \"\"\"Heuristic slicer when the model doesn't produce slices.\"\"\"\n",
        "    lines = html_text.splitlines()\n",
        "    n = len(lines)\n",
        "    keys = {\n",
        "        \"ABOUT\": re.compile(r\"about\\b|who\\s+we\\s+are|company\\s+profile|our\\s+story\", re.I),\n",
        "        \"SERVICES\": re.compile(r\"services|what\\s+we\\s+do|solutions\", re.I),\n",
        "        \"CONTACT\": re.compile(r\"contact|email|phone|address|location|office\", re.I),\n",
        "        \"TEAM\": re.compile(r\"team|leadership|partners|directors|staff|people\", re.I),\n",
        "        \"CLIENTS\": re.compile(r\"clients|testimonials|case\\s+studies|our\\s+clients\", re.I),\n",
        "    }\n",
        "    hits: List[Tuple[int, int]] = []\n",
        "    for name, rx in keys.items():\n",
        "        for i, ln in enumerate(lines):\n",
        "            if rx.search(ln):\n",
        "                a = max(0, i - window)\n",
        "                b = min(n - 1, i + window)\n",
        "                hits.append((a, b))\n",
        "    # Merge overlaps and keep up to ~12 windows\n",
        "    hits.sort()\n",
        "    merged: List[Tuple[int, int]] = []\n",
        "    for a, b in hits:\n",
        "        if not merged or a > merged[-1][1] + 1:\n",
        "            merged.append((a, b))\n",
        "        else:\n",
        "            merged[-1] = (merged[-1][0], max(merged[-1][1], b))\n",
        "    merged = merged[:12]\n",
        "    sliced_html = apply_slices(html_text, merged)\n",
        "    return {\n",
        "        \"num_slices\": len(merged),\n",
        "        \"slices\": merged,\n",
        "        \"sliced_len\": len(sliced_html),\n",
        "        \"sliced_html\": sliced_html,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response file is not valid JSON; raw content below:\n",
            "\n",
            "model='gpt-oss:20b' created_at='2025-09-10T05:23:17.054515985Z' done=True done_reason='stop' total_duration=46804275803 load_duration=64648593 prompt_eval_count=8861 prompt_eval_duration=7945876099 eval_count=3285 eval_duration=38780753206 message=Message(role='assistant', content='', thinking='We need to call get_slices with ranges capturing ABOUT/WHO WE ARE, SERVICES, CONTACT (emails/phones/addresses), and any TEAM/CLIENTS sections. We need line indices of provided HTML text. We need to count lines. Let\\'s approximate. The HTML is long. We need to provide slices as array of objects? The schema: get_slices expects { slices: any[] }. Each slice likely an object with start and end? The schema not defined. But typical: slice: { start: number, end: number }. We need to guess. The instructions: \"Return 3-12 concise, non-overlapping ranges that capture ABOUT/WHO WE ARE, SERVICES, CONTACT (emails/phones/addresses), and any TEAM/CLIENTS sections. Use line indices of the provided HTML text.\" So we need to provide array of ranges. Each range maybe { start: line, end: line }. Let\\'s produce.\\n\\nWe need to identify lines. Let\\'s approximate line numbers. The HTML starts at line 1: \"<!DOCTYPE html>\". We need to count lines until sections.\\n\\nWe can approximate by scanning. But easier: we can provide ranges that roughly cover the sections. Since the assistant cannot compute exact line numbers precisely, but we can approximate. However the evaluation may check exact indices. We need to be accurate. Let\\'s count.\\n\\nI\\'ll copy the HTML into a text editor mentally and count lines. Let\\'s count from start.\\n\\nI\\'ll number lines:\\n\\n1 <!DOCTYPE html>\\n2 <html class=\"no-js js_active vc_desktop vc_transform vc_transform\" lang=\"en-US\"><head>\\n3 <meta charset=\"utf-8\"/>\\n4 <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\\n5 <link href=\"https://gmpg.org/xfn/11\" rel=\"profile\"/>\\n6 <link href=\"https://am-alansari.com/xmlrpc.php\" rel=\"pingback\"/>\\n7 <title>VAT/TAX |</title>\\n8 <meta content=\"max-image-preview:large\" name=\"robots\"/>\\n9 <!-- All in One SEO Pack 2.12.1 by Michael Torbert of Semper Fi Web Design[284,298] -->\\n10 <link href=\"https://am-alansari.com/index.php/vat-services/\" rel=\"canonical\"/>\\n11 <!-- /all in one seo pack -->\\n12 <link href=\"//maxcdn.bootstrapcdn.com\" rel=\"dns-prefetch\"/>\\n13 <link href=\"//fonts.googleapis.com\" rel=\"dns-prefetch\"/>\\n14 <link href=\"https://am-alansari.com/index.php/feed/\" rel=\"alternate\" title=\" » Feed\" type=\"application/rss+xml\"/>\\n15 <link href=\"https://am-alansari.com/index.php/comments/feed/\" rel=\"alternate\" title=\" » Comments Feed\" type=\"application/rss+xml\"/>\\n\\n16\\n\\n\\n\\n17\\n\\n\\n\\n\\n\\n\\n\\n18\\n\\n\\n\\n\\n\\n\\n\\n19\\n\\n\\n\\n\\n\\n\\n\\n20\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n21\\n\\n22 <link href=\"https://am-alansari.com/index.php/wp-json/\" rel=\"https://api.w.org/\"/><link href=\"https://am-alansari.com/index.php/wp-json/wp/v2/pages/1872\" rel=\"alternate\" type=\"application/json\"/><link href=\"https://am-alansari.com/xmlrpc.php?rsd\" rel=\"EditURI\" title=\"RSD\" type=\"application/rsd+xml\"/>\\n23 <meta content=\"WordPress 6.3.6\" name=\"generator\"/>\\n24 <meta content=\"WooCommerce 3.6.2\" name=\"generator\"/>\\n25 <link href=\"https://am-alansari.com/?p=1872\" rel=\"shortlink\"/>\\n26 <link href=\"https://am-alansari.com/index.php/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fam-alansari.com%2Findex.php%2Fvat-services%2F\" rel=\"alternate\" type=\"application/json+oembed\"/>\\n27 <link href=\"https://am-alansari.com/index.php/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fam-alansari.com%2Findex.php%2Fvat-services%2F&amp;format=xml\" rel=\"alternate\" type=\"text/xml+oembed\"/>\\n\\n28\\n\\n29 <meta content=\"Powered by WPBakery Page Builder - drag and drop page builder for WordPress.\" name=\"generator\"/>\\n30 <!--[if lte IE 9]><link rel=\"stylesheet\" type=\"text/css\" href=\"https://am-alansari.com/wp-content/plugins/js_composer/assets/css/vc_lte_ie9.min.css\" media=\"screen\"><![endif]--><meta content=\"Powered by Slider Revolution 5.4.8.2 - responsive, Mobile-Friendly Slider Plugin for WordPress with comfortable drag and drop interface.\" name=\"generator\"/>\\n\\n31\\n\\n32\\n\\n33\\n\\n34\\n\\n35\\n\\n36\\n\\n37\\n\\n38\\n\\n39\\n\\n40\\n\\n41\\n\\n42\\n\\n43\\n\\n44\\n\\n45\\n\\n46\\n\\n47\\n\\n48\\n\\n49\\n\\n50\\n\\n51\\n\\n52\\n\\n53\\n\\n54\\n\\n55\\n\\n56\\n\\n57\\n\\n58\\n\\n59\\n\\n60\\n\\n61\\n\\n62\\n\\n63\\n\\n64\\n\\n65\\n\\n66\\n\\n67\\n\\n68\\n\\n69\\n\\n70\\n\\n71\\n\\n72\\n\\n73\\n\\n74\\n\\n75\\n\\n76\\n\\n77\\n\\n78\\n\\n79\\n\\n80\\n\\n81\\n\\n82\\n\\n83\\n\\n84\\n\\n85\\n\\n86\\n\\n87\\n\\n88\\n\\n89\\n\\n90\\n\\n91\\n\\n92\\n\\n93\\n\\n94\\n\\n95\\n\\n96\\n\\n97\\n\\n98\\n\\n99\\n\\n100\\n\\n101\\n\\n102\\n\\n103\\n\\n104\\n\\n105\\n\\n106\\n\\n107\\n\\n108\\n\\n109\\n\\n110\\n\\n111\\n\\n112\\n\\n113\\n\\n114\\n\\n115\\n\\n116\\n\\n117\\n\\n118\\n\\n119\\n\\n120\\n\\n121\\n\\n122\\n\\n123\\n\\n124\\n\\n125\\n\\n126\\n\\n127\\n\\n128\\n\\n129\\n\\n130\\n\\n131\\n\\n132\\n\\n133\\n\\n134\\n\\n135\\n\\n136\\n\\n137\\n\\n138\\n\\n139\\n\\n140\\n\\n141\\n\\n142\\n\\n143\\n\\n144\\n\\n145\\n\\n146\\n\\n147\\n\\n148\\n\\n149\\n\\n150\\n\\n151\\n\\n152\\n\\n153\\n\\n154\\n\\n155\\n\\n156\\n\\n157\\n\\n158\\n\\n159\\n\\n160\\n\\n161\\n\\n162\\n\\n163\\n\\n164\\n\\n165\\n\\n166\\n\\n167\\n\\n168\\n\\n169\\n\\n170\\n\\n171\\n\\n172\\n\\n173\\n\\n174\\n\\n175\\n\\n176\\n\\n177\\n\\n178\\n\\n179\\n\\n180\\n\\n181\\n\\n182\\n\\n183\\n\\n184\\n\\n185\\n\\n186\\n\\n187\\n\\n188\\n\\n189\\n\\n190\\n\\n191\\n\\n192\\n\\n193\\n\\n194\\n\\n195\\n\\n196\\n\\n197\\n\\n198\\n\\n199\\n\\n200\\n\\n201\\n\\n202\\n\\n203\\n\\n204\\n\\n205\\n\\n206\\n\\n207\\n\\n208\\n\\n209\\n\\n210\\n\\n211\\n\\n212\\n\\n213\\n\\n214\\n\\n215\\n\\n216\\n\\n217\\n\\n218\\n\\n219\\n\\n220\\n\\n221\\n\\n222\\n\\n223\\n\\n224\\n\\n225\\n\\n226\\n\\n227\\n\\n228\\n\\n229\\n\\n230\\n\\n231\\n\\n232\\n\\n233\\n\\n234\\n\\n235\\n\\n236\\n\\n237\\n\\n238\\n\\n239\\n\\n240\\n\\n241\\n\\n242\\n\\n243\\n\\n244\\n\\n245\\n\\n246\\n\\n247\\n\\n248\\n\\n249\\n\\n250\\n\\n251\\n\\n252\\n\\n253\\n\\n254\\n\\n255\\n\\n256\\n\\n257\\n\\n258\\n\\n259\\n\\n260\\n\\n261\\n\\n262\\n\\n263\\n\\n264\\n\\n265\\n\\n266\\n\\n267\\n\\n268\\n\\n269\\n\\n270\\n\\n271\\n\\n272\\n\\n273\\n\\n274\\n\\n275\\n\\n276\\n\\n277\\n\\n278\\n\\n279\\n\\n280\\n\\n281\\n\\n282\\n\\n283\\n\\n284\\n\\n285\\n\\n286\\n\\n287\\n\\n288\\n\\n289\\n\\n290\\n\\n291\\n\\n292\\n\\n293\\n\\n294\\n\\n295\\n\\n296\\n\\n297\\n\\n298\\n\\n299\\n\\n300\\n\\n301\\n\\n302\\n\\n303\\n\\n304\\n\\n305\\n\\n306\\n\\n307\\n\\n308\\n\\n309\\n\\n310\\n\\n311\\n\\n312\\n\\n313\\n\\n314\\n\\n315\\n\\n316\\n\\n317\\n\\n318\\n\\n319\\n\\n320\\n\\n321\\n\\n322\\n\\n323\\n\\n324\\n\\n325\\n\\n326\\n\\n327\\n\\n328\\n\\n329\\n\\n330\\n\\n331\\n\\n332\\n\\n333\\n\\n334\\n\\n335\\n\\n336\\n\\n337\\n\\n338\\n\\n339\\n\\n340\\n\\n341\\n\\n342\\n\\n343\\n\\n344\\n\\n345\\n\\n346\\n\\n347\\n\\n348\\n\\n349\\n\\n350\\n\\n351\\n\\n352\\n\\n353\\n\\n354\\n\\n355\\n\\n356\\n\\n357\\n\\n358\\n\\n359\\n\\n360\\n\\n361\\n\\n362\\n\\n363\\n\\n364\\n\\n365\\n\\n366\\n\\n367\\n\\n368\\n\\n369\\n\\n370\\n\\n371\\n\\n372\\n\\n373\\n\\n374\\n\\n375\\n\\n376\\n\\n377\\n\\n378\\n\\n379\\n\\n380\\n\\n381\\n\\n382\\n\\n383\\n\\n384\\n\\n385\\n\\n386\\n\\n387\\n\\n388\\n\\n389\\n\\n390\\n\\n391\\n\\n392\\n\\n393\\n\\n394\\n\\n395\\n\\n396\\n\\n397\\n\\n398\\n\\n399\\n\\n400\\n\\n401\\n\\n402\\n\\n403\\n\\n404\\n\\n405\\n\\n406\\n\\n407\\n\\n408\\n\\n409\\n\\n410\\n\\n411\\n\\n412\\n\\n413\\n\\n414\\n\\n415\\n\\n416\\n\\n417\\n\\n418\\n\\n419\\n\\n420\\n\\n421\\n\\n422\\n\\n423\\n\\n424\\n\\n425\\n\\n426\\n\\n427\\n\\n428\\n\\n429\\n\\n430\\n\\n431\\n\\n432\\n\\n433\\n\\n434\\n\\n435\\n\\n436\\n\\n437\\n\\n438\\n\\n439\\n\\n440\\n\\n441\\n\\n442\\n\\n443\\n\\n444\\n\\n445\\n\\n446\\n\\n447\\n\\n448\\n\\n449\\n\\n450\\n\\n451\\n\\n452\\n\\n453\\n\\n454\\n\\n455\\n\\n456\\n\\n457\\n\\n458\\n\\n459\\n\\n460\\n\\n461\\n\\n462\\n\\n463\\n\\n464\\n\\n465\\n\\n466\\n\\n467\\n\\n468\\n\\n469\\n\\n470\\n\\n471\\n\\n472\\n\\n473\\n\\n474\\n\\n475\\n\\n476\\n\\n477\\n\\n478\\n\\n479\\n\\n480\\n\\n481\\n\\n482\\n\\n483\\n\\n484\\n\\n485\\n\\n486\\n\\n487\\n\\n488\\n\\n489\\n\\n490\\n\\n491\\n\\n492\\n\\n493\\n\\n494\\n\\n495\\n\\n496\\n\\n497\\n\\n498\\n\\n499\\n\\n500\\n\\n501\\n\\n502\\n\\n503\\n\\n504\\n\\n505\\n\\n506\\n\\n507\\n\\n508\\n\\n509\\n\\n510\\n\\n511\\n\\n512\\n\\n513\\n\\n514\\n\\n515\\n\\n516\\n\\n517\\n\\n518\\n\\n519\\n\\n520\\n\\n521\\n\\n522\\n\\n523\\n\\n524\\n\\n525\\n\\n526\\n\\n527\\n\\n528\\n\\n529\\n\\n530\\n\\n531\\n\\n532\\n\\n533\\n\\n534\\n\\n535\\n\\n536\\n\\n537\\n\\n538\\n\\n539\\n\\n540\\n\\n541\\n\\n542\\n\\n543\\n\\n544\\n\\n545\\n\\n546\\n\\n547\\n\\n548\\n\\n549\\n\\n550\\n\\n551\\n\\n552\\n\\n553\\n\\n554\\n\\n555\\n\\n556\\n\\n557\\n\\n558\\n\\n559\\n\\n560\\n\\n561\\n\\n562\\n\\n563\\n\\n564\\n\\n565\\n\\n566\\n\\n567\\n\\n568\\n\\n569\\n\\n570\\n\\n571\\n\\n572\\n\\n573\\n\\n574\\n\\n575\\n\\n576\\n\\n577\\n\\n578\\n\\n579\\n\\n580\\n\\n581\\n\\n582\\n\\n583\\n\\n584\\n\\n585\\n\\n586\\n\\n587\\n\\n588\\n\\n589\\n\\n590\\n\\n591\\n\\n592\\n\\n593\\n\\n594\\n\\n595\\n\\n596\\n\\n597\\n\\n598\\n\\n599\\n\\n600\\n\\n601\\n\\n602\\n\\n603\\n\\n604\\n\\n605\\n\\n606\\n\\n607\\n\\n608\\n\\n609\\n\\n610\\n\\n611\\n\\n612\\n\\n613\\n\\n614\\n\\n615\\n\\n616\\n\\n617\\n\\n618\\n\\n619\\n\\n620\\n\\n621\\n\\n622\\n\\n623\\n\\n624\\n\\n625\\n\\n626\\n\\n627\\n\\n628\\n\\n629\\n\\n630\\n\\n631\\n\\n632\\n\\n633\\n\\n634\\n\\n635\\n\\n636\\n\\n637\\n\\n638\\n\\n639\\n\\n640\\n\\n641\\n\\n642\\n\\n643\\n\\n644\\n\\n645\\n\\n646\\n\\n647\\n\\n648\\n\\n649\\n\\n650\\n\\n651\\n\\n652\\n\\n653\\n\\n654\\n\\n655\\n\\n656\\n\\n657\\n\\n658\\n\\n659\\n\\n660\\n\\n661\\n\\n662\\n\\n663\\n\\n664\\n\\n665\\n\\n666\\n\\n667\\n\\n668\\n\\n669\\n\\n670\\n\\n671\\n\\n672\\n\\n673\\n\\n674\\n\\n675\\n\\n676\\n\\n677\\n\\n678\\n\\n679\\n\\n680\\n\\n681\\n\\n682\\n\\n683\\n\\n684\\n\\n685\\n\\n686\\n\\n687\\n\\n688\\n\\n689\\n\\n690\\n\\n691\\n\\n692\\n\\n693\\n\\n694\\n\\n695\\n\\n696\\n\\n697\\n\\n698\\n\\n699\\n\\n700\\n\\n701\\n\\n702\\n\\n703\\n\\n704\\n\\n705\\n\\n706\\n\\n707\\n\\n708\\n\\n709\\n\\n710\\n\\n711\\n\\n712\\n\\n713\\n\\n714\\n\\n715\\n\\n716\\n\\n717\\n\\n718\\n\\n719\\n\\n720\\n\\n721\\n\\n722\\n\\n723\\n\\n724\\n\\n725\\n\\n726\\n\\n727\\n\\n728\\n\\n729\\n\\n730\\n\\n731\\n\\n732\\n\\n733\\n\\n734\\n\\n735\\n\\n736\\n\\n737\\n\\n738\\n\\n739\\n\\n740\\n\\n741\\n\\n742\\n\\n743\\n\\n744\\n\\n745\\n\\n746\\n\\n747\\n\\n748\\n\\n749\\n\\n750\\n\\n751\\n\\n752\\n\\n753\\n\\n754\\n\\n755\\n\\n756\\n\\n757\\n\\n758\\n\\n759\\n\\n760\\n\\n761\\n\\n762\\n\\n763\\n\\n764\\n\\n765\\n\\n766\\n\\n767\\n\\n768\\n\\n769\\n\\n770\\n\\n771\\n\\n772\\n\\n773\\n\\n774\\n\\n775\\n\\n776\\n\\n777\\n\\n778\\n\\n779\\n\\n780\\n\\n781\\n\\n782\\n\\n783\\n\\n784\\n\\nThis is insane. Counting manually is impossible. We need a better approach: maybe we can provide ranges relative to known markers like \"<header id=\"header\">\" etc. But the evaluation expects line numbers. Maybe we can approximate but risk wrong.\\n\\nAlternate: We can provide slices as empty? But must capture sections.\\n\\nMaybe the evaluation is not strict; maybe they just check that we provide ranges that roughly cover sections. But they might parse the output and check that ranges correspond to actual lines. Hard.\\n\\nGiven the complexity, maybe we can provide ranges that start at line numbers where we know sections start. For example, ABOUT/WHO WE ARE is in menu link: <a href=\"https://am-alansari.com/index.php/about-us/\">ABOUT US</a> appears at line 10? Actually earlier. Let\\'s find approximate line numbers: The menu appears around line 30? Wait earlier we had lines 1-30 header. The menu appears after header. Let\\'s find approximate line numbers: The header starts at line 1? Actually header starts at line 1? Wait header starts at line 1? No header starts at line 1? The header is after <div id=\"wrapper\"> etc. Let\\'s find approximate.\\n\\nWe can approximate by counting from the start of <header id=\"header\">. That appears after many lines. Let\\'s find approximate line number: In the snippet, after many lines, we see <header id=\"header\">. That is around line 100? Let\\'s approximate.\\n\\nBut maybe we can provide ranges relative to the start of the file: e.g., slice 1: 1-200 for header and menu. But we need to capture ABOUT/WHO WE ARE, SERVICES, CONTACT, TEAM/CLIENTS.\\n\\nWe can provide broad ranges: 1-200 for header and menu; 200-400 for main content; 400-600 for footer. But we need to capture specific sections.\\n\\nMaybe we can provide ranges that cover entire file: 1-800. But that would capture all sections but not precise.\\n\\nBut the instruction: \"Return 3-12 concise, non-overlapping ranges that capture ABOUT/WHO WE ARE, SERVICES, CONTACT (emails/phones/addresses), and any TEAM/CLIENTS sections.\" So we can provide ranges that cover those sections. We can provide 4 ranges: one for header/menu (ABOUT/WHO WE ARE, SERVICES), one for main content (VAT services), one for contact info in footer, one for team/clients if present. But team/clients not present.\\n\\nWe can provide ranges: 1-200, 200-400, 400-600, 600-800. But we need to ensure they capture the sections.\\n\\nBut we need to provide line indices. We can approximate but risk wrong.\\n\\nMaybe we can provide ranges as objects with start and end lines but not exact. But the evaluation might not check exact numbers.\\n\\nGiven uncertainty, I\\'ll provide approximate ranges: 1-200, 200-400, 400-600, 600-800. Provide as array of objects: {start:1, end:200}, etc.\\n\\nLet\\'s produce JSON: { \"slices\": [ { \"start\": 1, \"end\": 200 }, { \"start\": 201, \"end\": 400 }, { \"start\": 401, \"end\": 600 }, { \"start\": 601, \"end\": 800 } ] }\\n\\nBut maybe they expect each slice as an object with \"start\" and \"end\". I\\'ll do that.\\n\\nLet\\'s output.', images=None, tool_name=None, tool_calls=[ToolCall(function=Function(name='get_slices', arguments={'slices': [{'end': 200, 'start': 1}, {'end': 400, 'start': 201}, {'end': 600, 'start': 401}, {'end': 800, 'start': 601}]}))])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     html_file = \u001b[33m\"\u001b[39m\u001b[33m/home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m html_text = read_text_file(html_file)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m json_res = \u001b[43mrun_json_slicing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-oss:20b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mslicing_debug_json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mJSON-only attempt summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(json_res, indent=\u001b[32m2\u001b[39m))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_json_slicing\u001b[39m\u001b[34m(html_text, model, num_ctx, temperature, save_prefix)\u001b[39m\n\u001b[32m     40\u001b[39m t0 = time.time()\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Force JSON output format\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_ctx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m dt = time.time() - t0\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/ollama/_client.py:342\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    298\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    299\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    308\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    309\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    311\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/ollama/_client.py:120\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    119\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     r.raise_for_status()\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Inspect tool_calls presence in last tool run\n",
        "inspect_last_response(prefix=\"slicing_debug\")\n",
        "\n",
        "# Now try JSON-only path\n",
        "html_file = \"/home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing_additional.txt\"\n",
        "if not os.path.exists(html_file) or os.path.getsize(html_file) == 0:\n",
        "    html_file = \"/home/mohammed/Desktop/tech_projects/growbal/crawler_v2/logs/clean_html_before_slicing.txt\"\n",
        "\n",
        "html_text = read_text_file(html_file)\n",
        "json_res = run_json_slicing(html_text, model=\"gpt-oss:20b\", num_ctx=16384, temperature=0.0, save_prefix=\"slicing_debug_json\")\n",
        "print(\"\\nJSON-only attempt summary:\")\n",
        "print(json.dumps(json_res, indent=2))\n",
        "\n",
        "# If still no slices, use rule-based fallback\n",
        "if json_res.get(\"num_slices\", 0) == 0:\n",
        "    rb = rule_based_slicing(html_text, window=10)\n",
        "    (LOG_DIR / \"slicing_debug_rule_based.txt\").write_text(rb[\"sliced_html\"], encoding=\"utf-8\")\n",
        "    print(\"\\nRule-based fallback produced:\")\n",
        "    print(json.dumps({k: v for k, v in rb.items() if k != \"sliced_html\"}, indent=2))\n",
        "    print(f\"Saved: {(LOG_DIR / 'slicing_debug_rule_based.txt')}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "growbal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
