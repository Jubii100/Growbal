{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import pathlib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import Field\n",
    "from typing import Literal\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from __future__ import print_function\n",
    "import sib_api_v3_sdk\n",
    "from sib_api_v3_sdk.rest import ApiException\n",
    "from IPython.display import Markdown, display\n",
    "from typing import Optional\n",
    "\n",
    "llm_model = os.environ[\"LLM_VERSION\"]\n",
    "\n",
    "search_starters = [\"Digital Marketing Agencies\", \"Renewable Energy Companies\", \"Cybersecurity Firms\", \"Legal Services Providers\", \"Healthcare Consultancies\"]\n",
    "\n",
    "class ResultRelevance(BaseModel):\n",
    "    explanation: str\n",
    "    link: str\n",
    "\n",
    "class RelevanceCheckOutput(BaseModel):\n",
    "    relevant_results: List[ResultRelevance]\n",
    "\n",
    "class SqlCommand(BaseModel):\n",
    "    command: str\n",
    "\n",
    "class ServiceProviderMemberDetails(BaseModel):\n",
    "    name: Optional[str]\n",
    "    role_description: Optional[str]\n",
    "    telephone: Optional[str]\n",
    "    mobile: Optional[str]\n",
    "    email: Optional[str]\n",
    "    linkedin: Optional[str]\n",
    "    facebook: Optional[str]\n",
    "    instagram: Optional[str]\n",
    "    twitter: Optional[str]\n",
    "    additional_info: Optional[str]\n",
    "\n",
    "class ServiceProviderOutput(BaseModel):\n",
    "    service_description: Optional[str]\n",
    "    rating: Optional[str]\n",
    "    pricing: Optional[str]\n",
    "    provider_type: Optional[str] = \"Company\"\n",
    "    country: Optional[str]\n",
    "    name: Optional[str]\n",
    "    logo: Optional[str]\n",
    "    website: Optional[str]\n",
    "    linkedin: Optional[str]\n",
    "    facebook: Optional[str]\n",
    "    instagram: Optional[str]\n",
    "    telephone: Optional[str]\n",
    "    mobile: Optional[str]\n",
    "    emails: Optional[str]\n",
    "    office_locations: Optional[str]\n",
    "    key_individuals: Optional[str]\n",
    "    service_provider_member_details: Optional[List[ServiceProviderMemberDetails]]\n",
    "\n",
    "class SearchTermsOutput(BaseModel):\n",
    "    search_terms: List[str]\n",
    "\n",
    "class AboutUsOutput(BaseModel):\n",
    "    about_us_link: Optional[List[str]]\n",
    "\n",
    "def search_serper(search_query):\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "        \"q\": search_query,\n",
    "        \"gl\": \"ae\", \n",
    "        \"num\": 10,\n",
    "        \"tbs\": \"qdr:d\"\n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'X-API-KEY': os.environ[\"SERPER_API_KEY\"],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    results = json.loads(response.text)\n",
    "    results_list = results['organic']\n",
    "\n",
    "    all_results = []\n",
    "    for id, result in enumerate(results_list, 1):\n",
    "        result_dict = {\n",
    "            'title': result['title'],\n",
    "            'link': result['link'],\n",
    "            'snippet': result['snippet'],\n",
    "            'search_term': search_query,\n",
    "            'id': id\n",
    "        }\n",
    "        all_results.append(result_dict)\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# def load_prompt(prompt_name, html_content=None, sql_schema=None):\n",
    "#     if prompt_name == \"generate_sql\":\n",
    "#         if not html_content or not sql_schema:\n",
    "#             raise ValueError(\"html_content and sql_schema must be provided for 'generate_sql' prompt.\")\n",
    "\n",
    "#         prompt = f\"\"\"\n",
    "# You are given HTML webpage content. Extract the details precisely:\n",
    "\n",
    "# - Business name, description, category, country of origin.\n",
    "# - Each office location city and country.\n",
    "# - Staff member details: name, position, email, phone, and social media accounts.\n",
    "\n",
    "# Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
    "\n",
    "# {sql_schema}\n",
    "\n",
    "# Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
    "\n",
    "# Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
    "\n",
    "# HTML Content:\n",
    "# {html_content}\n",
    "# \"\"\"\n",
    "#         return prompt\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported prompt_name '{prompt_name}'\")\n",
    "\n",
    "def load_prompt(prompt_name):\n",
    "    with open(f\"prompts/{prompt_name}.md\", \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "\n",
    "def check_search_relevance(search_term: str, search_results: Dict[str, Any]) -> RelevanceCheckOutput:\n",
    "    \"\"\"\n",
    "    Analyze search results and determine the most relevant ones.\n",
    "    \n",
    "    Args:\n",
    "        search_results: Dictionary containing search results to analyze\n",
    "        \n",
    "    Returns:\n",
    "        RelevanceCheckOutput containing the most relevant results and explanation\n",
    "    \"\"\"\n",
    "    prompt = load_prompt(\"relevance_check\")\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", prompt)\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(RelevanceCheckOutput)\n",
    "    llm_chain = prompt_template | llm\n",
    "    \n",
    "    return llm_chain.invoke({\"search_term\": search_term, 'search_results': search_results})\n",
    "\n",
    "\n",
    "def convert_html_to_markdown(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Headers\n",
    "    for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        level = int(h.name[1])\n",
    "        h.replace_with('#' * level + ' ' + h.get_text() + '\\n\\n')\n",
    "    \n",
    "    # Links\n",
    "    for a in soup.find_all('a'):\n",
    "        href = a.get('href', '')\n",
    "        text = a.get_text()\n",
    "        if href and text:\n",
    "            a.replace_with(f'[{text}]({href})')\n",
    "    \n",
    "    # Bold\n",
    "    for b in soup.find_all(['b', 'strong']):\n",
    "        b.replace_with(f'**{b.get_text()}**')\n",
    "    \n",
    "    # Italic\n",
    "    for i in soup.find_all(['i', 'em']):\n",
    "        i.replace_with(f'*{i.get_text()}*')\n",
    "    \n",
    "    # Lists\n",
    "    for ul in soup.find_all('ul'):\n",
    "        for li in ul.find_all('li'):\n",
    "            li.replace_with(f'- {li.get_text()}\\n')\n",
    "    \n",
    "    for ol in soup.find_all('ol'):\n",
    "        for i, li in enumerate(ol.find_all('li'), 1):\n",
    "            li.replace_with(f'{i}. {li.get_text()}\\n')\n",
    "    \n",
    "    # Get text and clean up\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Remove excess whitespace/newlines\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def scrape_and_save_markdown(relevant_results):\n",
    "    \"\"\"\n",
    "    Scrapes HTML content from URLs in relevant_results and saves as markdown files.\n",
    "    \n",
    "    Args:\n",
    "        relevant_results: List of dictionaries containing search results with URLs\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing markdown content and metadata\n",
    "    \"\"\"\n",
    "    # Create scraped_html directory if it doesn't exist\n",
    "    # pathlib.Path(\"scraped_markdown\").mkdir(exist_ok=True)\n",
    "\n",
    "    markdown_contents = []\n",
    "    for result in relevant_results:\n",
    "        if 'link' in result:\n",
    "            payload = {\n",
    "                \"api_key\": os.environ[\"SCRAPING_API_KEY\"], \n",
    "                \"url\": result['link'],\n",
    "                \"render_js\": \"true\"\n",
    "            }\n",
    "\n",
    "            response = requests.get(\"https://scraping.narf.ai/api/v1/\", params=payload)\n",
    "            if response.status_code == 200:\n",
    "                # Create filename from ID or URL if ID not available\n",
    "                # filename = f\"{result.get('id', hash(result['link']))}.md\"\n",
    "                # filepath = os.path.join(\"scraped_markdown\", filename)\n",
    "                \n",
    "                # Convert HTML to markdown\n",
    "                markdown_content = convert_html_to_markdown(response.content.decode())\n",
    "                \n",
    "                # Save markdown content to file\n",
    "                # with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                #     f.write(markdown_content)\n",
    "                \n",
    "                markdown_contents.append({\n",
    "                    'url': result['link'],\n",
    "                    # 'filepath': filepath,\n",
    "                    'markdown': markdown_content,\n",
    "                    'title': result.get('title', ''),\n",
    "                    'id': result.get('id', '')\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Failed to fetch {result['link']}: Status code {response.status_code}\")\n",
    "\n",
    "    # print(f\"Successfully downloaded and saved {len(markdown_contents)} pages as markdown to scraped_markdown/\")\n",
    "    print(f\"Successfully downloaded and saved {len(markdown_contents)} pages as markdown\")\n",
    "    return markdown_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_results = []\n",
    "for search_term in search_terms:\n",
    "    python_results = search_serper(search_term)\n",
    "    results = check_search_relevance(python_results)\n",
    "    \n",
    "    relevant_ids = [r.id for r in results.relevant_results]\n",
    "    \n",
    "    filtered_results = [r for r in python_results if str(r['id']) in relevant_ids]\n",
    "    \n",
    "    relevant_results.extend(filtered_results)\n",
    "\n",
    "markdown_contents = scrape_and_save_markdown(relevant_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_sql(html_content, sql_schema):\n",
    "#     \"\"\"\n",
    "#     Generates SQL for markdown content using GPT-4.\n",
    "    \n",
    "#     Args:\n",
    "#         html_content: HTML content of the webpage\n",
    "#         sql_schema: SQL schema for the database\n",
    "        \n",
    "#     Returns:\n",
    "#         SQL commands for the database\n",
    "#     \"\"\"\n",
    "#     # Load the summary prompt\n",
    "#     sql_generation_prompt = load_prompt(\"generate_sql\", html_content, sql_schema)\n",
    "\n",
    "#     # Create prompt template\n",
    "#     sql_generation_template = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", sql_generation_prompt)\n",
    "#     ])\n",
    "\n",
    "#     # Initialize LLM\n",
    "#     llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model)\n",
    "#     summary_chain = sql_generation_template | llm\n",
    "\n",
    "#     # Generate and save summaries\n",
    "#     summaries = []\n",
    "#     for content in markdown_contents:\n",
    "#         try:\n",
    "#             # Generate summary, limiting to first 2000 words\n",
    "#             summary = summary_chain.invoke({\n",
    "#                 'markdown_input': ' '.join(content['markdown'].split()[:3000])\n",
    "#                 # 'markdown_input': content['markdown']\n",
    "#             })\n",
    "            \n",
    "#             # Create filename for summary\n",
    "#             # summary_filename = f\"summary_{content['id']}.md\"\n",
    "#             # summary_filepath = os.path.join(\"markdown_summaries\", summary_filename)\n",
    "            \n",
    "#             # Save summary to file\n",
    "#             # with open(summary_filepath, 'w', encoding='utf-8') as f:\n",
    "#             #     f.write(summary.content)\n",
    "            \n",
    "#             # Add to summaries list\n",
    "#             summaries.append({\n",
    "#                 'markdown_summary': summary.content,\n",
    "#                 'url': content['url']\n",
    "#             })\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to summarize {content['url']}: {str(e)}\")\n",
    "\n",
    "#     # print(f\"Successfully generated summaries for {len(markdown_contents)} pages in markdown_summaries/\")\n",
    "#     print(f\"Successfully generated summaries for {len(markdown_contents)} pages\")\n",
    "#     return summaries\n",
    "\n",
    "# def generate_field_values(html_content, fields):\n",
    "#     # Load the summary prompt\n",
    "#     field_values_prompt = load_prompt(\"generate_sql\", html_content, sql_schema)\n",
    "\n",
    "#     # Create prompt template\n",
    "#     field_values_template = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", field_values_prompt)\n",
    "#     ])\n",
    "\n",
    "#     # Initialize LLM\n",
    "#     llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model)\n",
    "#     field_values_chain = field_values_template | llm\n",
    "\n",
    "#     # Generate and save summaries\n",
    "#     summaries = []\n",
    "#     for content in markdown_contents:\n",
    "#         try:\n",
    "#             # Generate summary, limiting to first 2000 words\n",
    "#             summary = field_values_chain.invoke({\n",
    "#                 'markdown_input': ' '.join(content['markdown'].split()[:3000])\n",
    "#                 # 'markdown_input': content['markdown']\n",
    "#             })\n",
    "            \n",
    "#             # Create filename for summary\n",
    "#             # summary_filename = f\"summary_{content['id']}.md\"\n",
    "#             # summary_filepath = os.path.join(\"markdown_summaries\", summary_filename)\n",
    "            \n",
    "#             # Save summary to file\n",
    "#             # with open(summary_filepath, 'w', encoding='utf-8') as f:\n",
    "#             #     f.write(summary.content)\n",
    "            \n",
    "#             # Add to summaries list\n",
    "#             summaries.append({\n",
    "#                 'markdown_summary': summary.content,\n",
    "#                 'url': content['url']\n",
    "#             })\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to summarize {content['url']}: {str(e)}\")\n",
    "\n",
    "#     # print(f\"Successfully generated summaries for {len(markdown_contents)} pages in markdown_summaries/\")\n",
    "#     print(f\"Successfully generated summaries for {len(markdown_contents)} pages\")\n",
    "#     return summaries\n",
    "\n",
    "# # summaries = generate_summaries(markdown_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = html_strings[1]\n",
    "sql_schema = \"\"\"-- Main table for Service model\n",
    "CREATE TABLE services_service (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    service_description TEXT NOT NULL DEFAULT '',\n",
    "    ratings VARCHAR(50) NOT NULL DEFAULT '',\n",
    "    pricing TEXT NOT NULL DEFAULT ''\n",
    ");\n",
    "\n",
    "-- Table for tags\n",
    "CREATE TABLE taggit_tag (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL UNIQUE,\n",
    "    slug VARCHAR(100) NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "-- Through-table for tags relation (TaggableManager)\n",
    "CREATE TABLE taggit_taggeditem (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    tag_id INTEGER NOT NULL REFERENCES taggit_tag(id) ON DELETE CASCADE,\n",
    "    content_type_id INTEGER NOT NULL REFERENCES django_content_type(id) ON DELETE CASCADE,\n",
    "    object_id INTEGER NOT NULL\n",
    ");\n",
    "\n",
    "-- Django automatically creates indexes:\n",
    "CREATE INDEX taggit_taggeditem_content_type_id_object_id_idx ON taggit_taggeditem(content_type_id, object_id);\n",
    "\n",
    "-- accounts/models.py\n",
    "CREATE TABLE accounts_serviceproviderprofile (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    user_id INTEGER UNIQUE REFERENCES auth_user(id) ON DELETE CASCADE,\n",
    "    service_id INTEGER REFERENCES services_service(id) ON DELETE SET NULL,\n",
    "    provider_type VARCHAR(50) NOT NULL DEFAULT 'Company',\n",
    "    country VARCHAR(100),\n",
    "    session_status VARCHAR(8) NOT NULL DEFAULT 'inactive',\n",
    "    tier VARCHAR(50),\n",
    "    name VARCHAR(255) NOT NULL DEFAULT 'Default Name',\n",
    "    logo VARCHAR(100),  -- ImageField stored as path string\n",
    "    website VARCHAR(200),\n",
    "    linkedin VARCHAR(200),\n",
    "    facebook VARCHAR(200),\n",
    "    instagram VARCHAR(200),\n",
    "    telephone VARCHAR(30),\n",
    "    mobile VARCHAR(30),\n",
    "    emails TEXT,\n",
    "    office_locations TEXT,\n",
    "    key_individuals TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE accounts_serviceprovidermemberprofile (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    user_id INTEGER UNIQUE REFERENCES auth_user(id) ON DELETE CASCADE,\n",
    "    company_id INTEGER REFERENCES accounts_serviceproviderprofile(id) ON DELETE CASCADE,\n",
    "    role_description VARCHAR(255),\n",
    "    telephone VARCHAR(30),\n",
    "    mobile VARCHAR(30),\n",
    "    email VARCHAR(254),\n",
    "    linkedin VARCHAR(200),\n",
    "    facebook VARCHAR(200),\n",
    "    instagram VARCHAR(200),\n",
    "    twitter VARCHAR(200),\n",
    "    additional_info TEXT\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'growbal'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# # Example usage:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from .django.accounts.management.create_or_get_user import get_or_create_user\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# user_email = \"jonathon.davidson@example.com\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrowbal_django\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccounts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmanagement\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcreate_or_get_user\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_or_create_user\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Now use the function directly\u001b[39;00m\n\u001b[32m     20\u001b[39m user_email = \u001b[33m\"\u001b[39m\u001b[33mjonathon.davidson@example.com\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/tech_projects/growbal/growbal_django/accounts/management/create_or_get_user.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Setup Django environment (replace 'your_project_name' with your project's actual name)\u001b[39;00m\n\u001b[32m      5\u001b[39m os.environ.setdefault(\u001b[33m'\u001b[39m\u001b[33mDJANGO_SETTINGS_MODULE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgrowbal.settings\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdjango\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maccounts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CustomUser\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdjango\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntegrityError\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/django/__init__.py:19\u001b[39m, in \u001b[36msetup\u001b[39m\u001b[34m(set_prefix)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdjango\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01murls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_script_prefix\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdjango\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlog\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m configure_logging\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m configure_logging(\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLOGGING_CONFIG\u001b[49m, settings.LOGGING)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m set_prefix:\n\u001b[32m     21\u001b[39m     set_script_prefix(\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m settings.FORCE_SCRIPT_NAME \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m settings.FORCE_SCRIPT_NAME\n\u001b[32m     23\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/django/conf/__init__.py:81\u001b[39m, in \u001b[36mLazySettings.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the value of a setting and cache it in self.__dict__.\"\"\"\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (_wrapped := \u001b[38;5;28mself\u001b[39m._wrapped) \u001b[38;5;129;01mis\u001b[39;00m empty:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     _wrapped = \u001b[38;5;28mself\u001b[39m._wrapped\n\u001b[32m     83\u001b[39m val = \u001b[38;5;28mgetattr\u001b[39m(_wrapped, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/django/conf/__init__.py:68\u001b[39m, in \u001b[36mLazySettings._setup\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m     60\u001b[39m     desc = (\u001b[33m\"\u001b[39m\u001b[33msetting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msettings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ImproperlyConfigured(\n\u001b[32m     62\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRequested \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, but settings are not configured. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must either define the environment variable \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor call settings.configure() before accessing settings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     65\u001b[39m         % (desc, ENVIRONMENT_VARIABLE)\n\u001b[32m     66\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28mself\u001b[39m._wrapped = \u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/django/conf/__init__.py:166\u001b[39m, in \u001b[36mSettings.__init__\u001b[39m\u001b[34m(self, settings_module)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# store the settings module in case someone later cares\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mself\u001b[39m.SETTINGS_MODULE = settings_module\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m mod = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSETTINGS_MODULE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m tuple_settings = (\n\u001b[32m    169\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mALLOWED_HOSTS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mINSTALLED_APPS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    173\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSECRET_KEY_FALLBACKS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    174\u001b[39m )\n\u001b[32m    175\u001b[39m \u001b[38;5;28mself\u001b[39m._explicit_settings = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'growbal'"
     ]
    }
   ],
   "source": [
    "# # Example usage:\n",
    "# from .django.accounts.management.create_or_get_user import get_or_create_user\n",
    "# user_email = \"jonathon.davidson@example.com\"\n",
    "# user_username = \"jonathon.davidson\"\n",
    "# user_password = \"securepassword123\"\n",
    "\n",
    "# user_id = get_or_create_user(user_email, user_username, user_password)\n",
    "\n",
    "# print(f\"User ID: {user_id}\")\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, '/home/mohammed/Desktop/tech_projects/growbal')\n",
    "# import django\n",
    "# print(django.__path__)\n",
    "\n",
    "# try:\n",
    "from growbal_django.accounts.management.create_or_get_user import get_or_create_user\n",
    "\n",
    "# Now use the function directly\n",
    "user_email = \"jonathon.davidson@example.com\"\n",
    "user_username = \"jonathon.davidson\"\n",
    "user_password = \"securepassword123\"\n",
    "\n",
    "user_id = get_or_create_user(email=user_email, username=user_username, password=user_password)\n",
    "print(f\"User ID: {user_id}\")\n",
    "\n",
    "# finally:\n",
    "#     sys.path.remove('/home/mohammed/Desktop/tech_projects/growbal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import django\n",
    "import sys\n",
    "from asgiref.sync import sync_to_async\n",
    "\n",
    "# # Path to your Django project root (adjust if necessary)\n",
    "sys.path.insert(0, '/home/mohammed/Desktop/tech_projects/growbal/growbal_django')\n",
    "\n",
    "# Set Django settings module (replace with your actual settings module path)\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"growbal.settings\")\n",
    "\n",
    "# Initialize Django environment\n",
    "django.setup()\n",
    "\n",
    "# from growbal_django.accounts.models import CustomUser\n",
    "from accounts.models import CustomUser\n",
    "\n",
    "# Wrap synchronous ORM calls in sync_to_async\n",
    "@sync_to_async\n",
    "def get_or_create_user(email, username, password):\n",
    "    user, created = CustomUser.objects.get_or_create(\n",
    "        email=email,\n",
    "        defaults={'username': username}\n",
    "    )\n",
    "    if created and password:\n",
    "        user.set_password(password)\n",
    "        user.save()\n",
    "    return user.id\n",
    "\n",
    "user_email = \"jonathon.davidson@example.com\"\n",
    "user_username = \"jonathon.davidson\"\n",
    "user_password = \"securepassword123\"\n",
    "\n",
    "# If running in Jupyter or an async context, call as follows:\n",
    "user_id = await get_or_create_user(user_email, user_username, user_password)\n",
    "\n",
    "print(f\"User ID: {user_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "# Role\n",
      "\n",
      "You are an accurate and experienced data engineer.\n",
      "\n",
      "# Task\n",
      "\n",
      "You will receive HTML webpage content. Extract the following fields exactly:\n",
      "\n",
      "- service_description, rating, pricing.\n",
      "- provider_type (has to be either Company or Agent), country (has to be one of ('UAE', 'UK', 'USA')), name, logo (logo link), website, linkedin, facebook, instagram, telephone, mobile, emails, office locations, key individuals.\n",
      "- service_provider_member_details: name, role_description, telephone, mobile, email, linkedin, facebook, instagram, twitter, additional_info.\n",
      "\n",
      "Provide exactly a JSON object containing the extracted fields.\n",
      "\n",
      "HTML Content:\n",
      "\n",
      "{html_content}\n",
      "\n",
      "# Output\n",
      "\n",
      "Executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "html_content:\n",
      "\n",
      "<div>\n",
      "<p>Who We Are</p>\n",
      "<p>The region’s foremost boutique commercial and private client law firm. Our strength lies in providing expert guidance to our clients belonging to an array of industries.</p>\n",
      "<p>About Davidson & Co</p>\n",
      "<p>Davidson & Co was established by founding partner Jonathon Davidson in 2008 and continues to expand rapidly by attracting lawyers with significant experience of practising in Dubai and throughout the GCC.</p>\n",
      "<p>Our team includes lawyers and staff from the United Kingdom, United States, Australia, India, Pakistan and Lebanon. The firm’s mix of lawyers from all around the world allows us to accommodate clients by operating in a myriad of languages and cultures. The firm offers lawyers fluent in English, Arabic, Spanish, French, Hindi, Urdu and Punjabi.</p>\n",
      "<p>Collectively as a firm our lawyers have over 50 years’ experience in the UAE, both in private practice with respected local and international law firms, and in industry with UAE government companies, NASDAQ and FTSE listed organisations.</p>\n",
      "<p>We are a member of Legalink, a global legal network comprising more than 60 independent business-oriented law firms. In addition we are also a member of the International Fraud Group (IFG), an alliance of over 30 handpicked law firms with a presence in over 50 countries, formed to combat cross-border fraud and recover stolen assets from jurisdictions around the world.</p>\n",
      "<p>With our depth of experience we can assist clients, both corporate and private, with the nuances of local business practises and the rigours of international commerce. Each member of our team strives to understand the needs of our clients’ businesses, to add value wherever possible, and to ensure ongoing development and success.</p>\n",
      "<p>Message from Our Founding Partner</p>\n",
      "<p>Jonathon is a dispute resolution lawyer and Founding Partner at Davidson & Co. Jonathon has 22 years dispute resolution experience and has acted in all manner of disputes for institutions, developers, investors and public companies, as well as for private companies and individuals.</p>\n",
      "<p>Mission Statement</p>\n",
      "<p>We are always one step ahead to advise on the changes in the law and serve our clients’ needs as they arise.</p>\n",
      "<p>We maximise opportunities for our clients whilst protecting their interests.</p>\n",
      "<p>We see ourselves as your partners in business as we too share the vision that the Rulers of the UAE have set for the years ahead.</p>\n",
      "<p>We recognise that for our clients to be risk takers and achieve their desired goals, sound legal and commercial advice is required from the beginning. Through our sector expertise and in-depth understanding of the region, we advise our clients on a range of legal services providing tailor-made advice to fit their individual needs.</p>\n",
      "<p>Core Values</p>\n",
      "<p>Davidson & Co is a unique hybrid of a local firm operated by lawyers drawn from across the globe, with international training and experience.</p>\n",
      "<p>We know that the ‘legal experience’ for clients who instruct us will be an enjoyable one, and we have created a very flexible, friendly, and efficient office which is designed to meet client needs in a seamless and stress free manner.</p>\n",
      "<p>We want to encourage fledgling businesses to come and work with us and draw upon our collective experience of more than 50 years in the region.</p>\n",
      "<p>This wide range and length of experience are as useful to established businesses as it is to new and young companies. We have a number of clients with AED billions in turnover, and we know that our dynamic and refreshing approach to the provision of legal services and is welcomed by both large and small companies alike.</p>\n",
      "<p>Language Capabilities</p>\n",
      "<p>Our mix of lawyers from all over the world means that we can operate in a myriad of languages and cultures. We have experience and connections with the UAE, and the wider Middle East, the UK, Europe, Australasia, US and CIS. In addition to English, we speak Arabic, Spanish, French, Hindi, Urdu and Punjabi.</p>\n",
      "<p>Rest assured if we can’t ourselves speak fluently in any particular language, we will have no difficulty in finding someone to help who can.</p>\n",
      "<p>Our USP is quality and the ability to deal with any problem or issue relating to you, or your business, within Dubai and the UAE.</p>\n",
      "<p>Hear from our Clients</p>\n",
      "<p>As a business coach to leading Dubai based executives I always look to partner with the best firms in the Middle East region. From my experiences Davidson & co always deliver to the highest level and know how to successfully undertake business in the region.</p>\n",
      "<p>Adam Ashcroft</p>\n",
      "<p>Hear From Our Clients</p>\n",
      "<p>They are a very respectful and relaible law firm and they provide their recommendation and advise that best suits the case taking into consider all aspects both the commercial and legal ones. I highly recommend them to everyone and I wish them all the best and success.</p>\n",
      "<p>Nour Khawatmi</p>\n",
      "<p>Hear from our Clients</p>\n",
      "<p>Thanks to Andy Lyons and the team at Davidson & Co for their quick and clear advice on some intricate UAE legal issues. They went above and beyond what I would have expected and were very approachable and professional in every respect. Would definitely recommend.</p>\n",
      "<p>Jamie Wallace</p>\n",
      "<p>Hear from our Clients</p>\n",
      "<p>As a business coach to leading Dubai based executives I always look to partner with the best firms in the Middle East region. From my experiences Davidson & co always deliver to the highest level and know how to successfully undertake business in the region.</p>\n",
      "<p>Benjamin Dawson</p>\n",
      "<p>Our Awards</p>\n",
      "<p>Stay Updated</p>\n",
      "<p>Stay ahead of the curve with Davidson & Co’s latest insights and legal updates. Subscribe to our newsletter and ensure you never miss out on critical legal developments and news.</p>\n",
      "</div>\n",
      "\n",
      "\n",
      "result:\n",
      "\n",
      "service_description='The region’s foremost boutique commercial and private client law firm. Our strength lies in providing expert guidance to our clients belonging to an array of industries. Davidson & Co was established by founding partner Jonathon Davidson in 2008 and continues to expand rapidly by attracting lawyers with significant experience of practising in Dubai and throughout the GCC. Our team includes lawyers and staff from the United Kingdom, United States, Australia, India, Pakistan and Lebanon. We are a member of Legalink, a global legal network comprising more than 60 independent business-oriented law firms. With our depth of experience we can assist clients, both corporate and private, with the nuances of local business practises and the rigours of international commerce.' rating=None pricing=None provider_type='Company' country='UAE' name='Davidson & Co' logo=None website=None linkedin=None facebook=None instagram=None telephone=None mobile=None emails=None office_locations=None key_individuals=None service_provider_member_details=[ServiceProviderMemberDetails(name='Jonathon Davidson', role_description='Jonathon is a dispute resolution lawyer and Founding Partner at Davidson & Co. Jonathon has 22 years dispute resolution experience and has acted in all manner of disputes for institutions, developers, investors and public companies, as well as for private companies and individuals.', telephone=None, mobile=None, email=None, linkedin=None, facebook=None, instagram=None, twitter=None, additional_info=None)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = load_prompt(\"generate_fields\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt)\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(ServiceProviderOutput)\n",
    "llm_chain = prompt_template | llm\n",
    "\n",
    "result = llm_chain.invoke({\"html_content\": html_strings[1]})\n",
    "\n",
    "print(\"prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\")\n",
    "# print(\"sql_schema:\\n\")\n",
    "# print(sql_schema)\n",
    "print(\"\\n\")\n",
    "print(\"html_content:\\n\")\n",
    "print(html_strings[1])\n",
    "print(\"\\n\")\n",
    "print(\"result:\\n\")\n",
    "print(result)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "# Role\n",
      "\n",
      "You are an expert at generating concise, targeted Google search terms specifically intended to discover official websites of companies or service providers within a given industry or those providing specific services.\n",
      "\n",
      "# Task\n",
      "\n",
      "Your generated search terms should effectively yield official company websites when entered into Google.\n",
      "\n",
      "Provide exactly a JSON object containing the extracted fields.\n",
      "\n",
      "Provided industry or service:\n",
      "{service}\n",
      "\n",
      "# Output\n",
      "\n",
      "A JSON object containing the extracted fields.\n",
      "\n",
      "\n",
      "\n",
      "result:\n",
      "\n",
      "search_terms=['Legal Services Providers official website', 'Law firms official site', 'Legal service company website', 'Authentic website of legal counselors', 'Official website attorney services', 'Official Law firm sites', 'Legal service provider online presence', 'Official legal consultancies sites', 'Best legal services company websites', 'Web portal official legal services']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = load_prompt(\"generate_search_terms\")\n",
    "service = search_starters[3]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt)\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(SearchTermsOutput)\n",
    "llm_chain = prompt_template | llm\n",
    "\n",
    "result = llm_chain.invoke({\"service\": service})\n",
    "\n",
    "print(\"prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\")\n",
    "print(\"result:\\n\")\n",
    "print(result)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "\n",
      "\n",
      "For each provided industry or service, generate exactly five targeted Google search queries.\n",
      "\n",
      "\n",
      "# Role\n",
      "\n",
      "You are an expert at generating concise, targeted Google search terms specifically intended to discover the \"About Us,\" \"Company Information,\" or general informational pages for companies within a given industry or those providing specific services.\n",
      "\n",
      "# Task\n",
      "\n",
      "Your generated search terms should effectively yield company profiles, service descriptions, or about pages when entered into Google.\n",
      "\n",
      "Provide exactly a JSON object containing the extracted fields.\n",
      "\n",
      "Provided industry or service:\n",
      "{service}\n",
      "\n",
      "# Output\n",
      "\n",
      "A JSON object containing the extracted fields.\n",
      "\n",
      "\n",
      "\n",
      "result:\n",
      "\n",
      "search_terms=['Digital Marketing Agencies company profile', 'About Us Digital Marketing Agencies', 'Digital Marketing services description', 'Company Information of Digital Marketing Agencies', 'Top Digital Marketing Agencies About Us']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\")\n",
    "print(\"result:\\n\")\n",
    "print(result)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# links = []\n",
    "for search_term in result.search_terms:\n",
    "    links = search_serper(search_term)\n",
    "    relevant_links = check_search_relevance(search_term, links)\n",
    "    # print(relevant_links)\n",
    "    break\n",
    "\n",
    "# print(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_results=[ResultRelevance(explanation=\"The title ('Dentons - Home') hints that this is the official site for Dentons, an international legal practice. The snippet further confirms that they offer legal services worldwide. Definitely worth exploring.\", link='https://www.dentons.com/en/'), ResultRelevance(explanation=\"Hill Dickinson's site seems worth visiting as the title reflects that it's an official website of an international law firm and the snippet emphasizes their role as a trusted legal service provider.\", link='https://www.hilldickinson.com/'), ResultRelevance(explanation='K&L Gates appear to be a global legal services provider and their title and snippet indicates this is their official website, mentioning both their global presence and client services like legal counsel.', link='https://www.klgates.com/'), ResultRelevance(explanation=\"Pinsent Masons' site is relevant because the title does not appear to be generic and suggests that this is an official Pinsent Masons web page. They describe themselves as a firm with 'law at the core' which fits our criteria.\", link='https://www.pinsentmasons.com/'), ResultRelevance(explanation=\"CMS is a law firm, which the title and the snippet prove. The title indicates that it's CMS' official website as it directly associates the name with law and tax services, providing these services on an international scale.\", link='https://cms.law/'), ResultRelevance(explanation=\"The title and snippet clearly indicate that this is Taylor Wessing's official site, a global law firm that offers various legal and corporate services.\", link='https://www.taylorwessing.com/en/'), ResultRelevance(explanation=\"Ogier's official website seems like a suitable pick because the title corroborates that they are a professional legal services firm, while the snippet alludes to their ability to handle complex transactions.\", link='https://www.ogier.com/'), ResultRelevance(explanation='The link for Stinson LLP appears to be their official site, the title associates the firm with legal services and the snippet indicates they work with a large range of clients, noting that they are a law firm.', link='https://www.stinson.com/'), ResultRelevance(explanation=\"Charles Russell Speechlys' official website is a strong candidate. The title and snippet show them as an international law firm focusing on private capital, which fits the legal service provider criteria of interest.\", link='https://www.charlesrussellspeechlys.com/en/')]\n"
     ]
    }
   ],
   "source": [
    "print(relevant_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about_us_link=['https://www.dentons.com/en/about-dentons', 'https://www.dentons.com/en/services-and-solutions']\n",
      "['https://www.dentons.com/en/about-dentons', 'https://www.dentons.com/en/services-and-solutions']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1297\n",
      "here\n",
      "1496\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ServiceProviderOutput' object has no attribute 'ServiceProviderOutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m     result = llm_chain.invoke({\u001b[33m\"\u001b[39m\u001b[33mhtml_content\u001b[39m\u001b[33m\"\u001b[39m: clean_html_sum})\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mServiceProviderOutput\u001b[49m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# print(nav_links)\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/pydantic/main.py:989\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ServiceProviderOutput' object has no attribute 'ServiceProviderOutput'"
     ]
    }
   ],
   "source": [
    "from scrapper import HtmlScraper\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "scraper = HtmlScraper(scraping_api_key=os.environ[\"SCRAPING_API_KEY\"])\n",
    "for relevant_link in relevant_links.relevant_results:\n",
    "    html_content = scraper.scrape_html(relevant_link.link)\n",
    "    nav_links = scraper.get_nav_links(html_content)\n",
    "    nav_links_str = \"\\n\".join([f\"{text}: {link}\" for text, link in nav_links])\n",
    "\n",
    "    prompt = load_prompt(\"generate_about_us_link\")\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", prompt)\n",
    "    ])\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(AboutUsOutput)\n",
    "    llm_chain = prompt_template | llm\n",
    "\n",
    "    result = llm_chain.invoke({\"nav_links\": nav_links_str})\n",
    "    print(result)\n",
    "    print(result.about_us_link)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    clean_html_sum = \"\"\n",
    "    i = 1\n",
    "    num_tokens_allowed = 9000\n",
    "    for link in result.about_us_link:\n",
    "        try:\n",
    "            html_content = scraper.scrape_html(link)\n",
    "            clean_text, clean_html = scraper.clean_html_content(html_content)\n",
    "            print(count_tokens(clean_html))\n",
    "            if count_tokens(clean_html) < num_tokens_allowed/len(result.about_us_link):\n",
    "                clean_html_sum += f\"HTML PAGE {i}: ({link})\\n\\n\"\n",
    "                clean_html_sum += clean_html + \"\\n\\n\"\n",
    "                print(\"here\")\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "    \n",
    "    # clean_html_sum = clean_html_sum[:num_tokens_allowed]\n",
    "    if clean_html_sum != \"\":\n",
    "        prompt = load_prompt(\"generate_fields\")\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", prompt)\n",
    "        ])\n",
    "        llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(ServiceProviderOutput)\n",
    "        llm_chain = prompt_template | llm\n",
    "        result = llm_chain.invoke({\"html_content\": clean_html_sum})\n",
    "        # print(result)\n",
    "        print(result)\n",
    "    # print(nav_links)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ServiceProviderOutput'>\n",
      "service_description=\"Dentons is the world's largest global law firm, offering a variety of services and solutions to help clients grow, protect, operate and finance their businesses. Their content and solutions are organized around the business agenda of the clients rather than their organizational structure. They offer practical toolkits and takeaways on various issues that General Counsels and in-house legal teams may find helpful which are all available in their on-demand offering 'CenterX'. They also stress on their continuous improvement methodology to ensure that the experience the clients have with Dentons is constantly advancing.\" rating=None pricing=None provider_type='Company' country=None name='Dentons' logo=None website='https://www.dentons.com/' linkedin=None facebook=None instagram=None telephone=None mobile=None emails=None office_locations=None key_individuals=None service_provider_member_details=None\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p>Join over 3,000 of your peers who have already registered for this award-winning global webinar program. Sessions are focused on bringing you practical insights on the biggest challenges and opportunities facing General Counsel and in-house legal teams.</p>\n",
      "<p>Our outstanding Ukrainian team continues to work with international clients investing in Ukraine. Follow our videos and podcasts with key market participants to hear more about the current business and investment climate. Up to date insights on key legal and market developments can also be found in our hub.</p>\n",
      "<p>We are consistently hearing from clients that AI is a key topic for in-house legal to address in 2025. Our report highlights the key areas of legal risk and gives a digestible and pragmatic global overview. Anyone with responsibility for their organization's legal or risk agenda will benefit from reviewing this report.</p>\n",
      "<p>How can you structure your global business in the most tax-efficient manner? This edition provides a high-level overview of the tax consequences that face businesses planning to expand international operations.</p>\n",
      "<h2 class=\"gpof-h-lg gpof-grey-dark gpof-font-semi-bold gpof-padding-nill-all ng-binding ng-scope\" ng-bind-html=\"htmlRenderer(gallery.Title)\" ng-if=\"gallery.Title &amp;&amp; gallery.Title !== ''\" ng-show=\"gallery.hideTitle == false\">Dentons' news from around the world</h2>\n",
      "<p>Dentons is proud to announce the successful closure of a US$300 million equivalent senior unsecured dual-currency term loan facility for Asakabank. The syndication was met with overwhelming interest, achieving a substantial oversubscription of 3.5 times the facility's launch amount. A total of 22 institutions from across the globe participated in the facilities, underscoring the strong international confidence in Asakabank and the Uzbek market.</p>\n",
      "<p>Dentons advised the French group Florimond Desprez on the creation of United Beet Seeds, a strategic joint venture with the Danish group DLF Seeds A/S. This major transaction marks a structuring step in the global sugar beet seed industry.</p>\n",
      "<p>Global law firm Dentons has advised Sousol Holdings Ltd. on the sale of a 54 MW ready-to-build wind project in Romania to Engie Romania S.A. The project, located in Constanta County, was sold at a ready-to-build stage, with all necessary building permits obtained to commence the works.</p>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about_us_link=None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<div>\n",
      "<html><body><p>We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services.</p></body></html>\n",
      "<html><body><p>optimizely_data$pending_eventsThis cookie is set to make split-tests on the website, which optimizes the website's relevance towards the visitor – the cookie can also be set to improve the visitor's experience on a website.</p></body></html>\n",
      "<html><body><p>Maximum Storage Duration: PersistentType: HTML Local Storage</p></body></html>\n",
      "<html><body><p>optimizelyEndUserIdUsed to measure how selected users react to targeted changes to the website's content and functionality, in order to determine what variation is most efficacious in terms of converting users to customers.</p></body></html>\n",
      "<html><body><p>SC_ANALYTICS_GLOBAL_COOKIEUsed by Sitecore Engagement Analytics to identify the visitor on repeat visits to the website.</p></body></html>\n",
      "<html><body><p>Maximum Storage Duration: 13 monthsType: HTTP Cookie</p></body></html>\n",
      "<div class=\"CybotCookiebotDialogDetailBodyContentCookieTypeIntro\">Marketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.</div>\n",
      "<html><body><p>optimizelyDomainTestCookie [x2]Tracks the conversion rate between the user and the advertisement banners on the website - This serves to optimise the relevance of the advertisements on the website.</p></body></html>\n",
      "<html><body><p>Maximum Storage Duration: 180 daysType: HTTP Cookie</p></body></html>\n",
      "<html><body><p>optimizelyOptOut [x2]Collects visitor data related to the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded, with the purpose of displaying targeted ads.</p></body></html>\n",
      "<html><body><p>WIDGET::local::broadcastUsed by audio-platform SoundCloud to implement, measure and improve their embedded content/service on the website - The collection of data also includes visitors’ interaction with embedded content/service. This can be used for statistics or marketing purposes.</p></body></html>\n",
      "<html><body><p>sp_landingUsed to implement audio-content from Spotify on the website. Can also be used to register user interaction and preferences in context with audio-content - This can serve statistics and marketing purposes.</p></body></html>\n",
      "<html><body><p>Maximum Storage Duration: 1 dayType: HTTP Cookie</p></body></html>\n",
      "<html><body><p>sp_tUsed to implement audio-content from Spotify on the website. Can also be used to register user interaction and preferences in context with audio-content - This can serve statistics and marketing purposes.</p></body></html>\n",
      "<h2 class=\"sector-focus__title\">Sector focus</h2>\n",
      "<h3 class=\"sector-focus__item-heading\">Technology, media &amp; communications</h3>\n",
      "<html><body><p>We are one of the most connected law firms ingrained in the technology, media and communications sectors. From seed stage to IPO, and from start-up to unicorn, we're one of the few firms who can support companies throughout their life cycle.</p></body></html>\n",
      "<h3 class=\"sector-focus__item-heading\">Private wealth</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1104px;\">Our international Private Wealth group has been recognised as a market leader for many years. We are one of the few international law firms able to provide a fully integrated legal service that addresses clients' business, investment and personal interests.</p>\n",
      "<h3 class=\"sector-focus__item-heading\">Real estate, infrastructure &amp; energy</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1104px;\">Through creating our unique Real Estate, Infrastructure &amp; Energy sector group, we are consolidating our broad cross-border strength and significant industry expertise in a single centre of excellence. We bring a one-team mindset and approach where it is needed for this cross-sector focus.</p>\n",
      "<h3 class=\"equal-height-item\" style=\"height: 165px;\">Other expertise</h3>\n",
      "<h2 class=\"key-services__title\">Key services</h2>\n",
      "<h3 class=\"key-services__link-text\">Corporate/M&amp;A &amp; capital markets</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1296px;\">Our international team has an outstanding record in cross-border M&amp;A. We support clients on deals of all shapes and sizes, and act on private capital investment work from set-up and early-stage funding to growth capital and private equity. We solve complicated issues with ease and make your deal a seamless experience.</p>\n",
      "<h3 class=\"key-services__link-text\">Data protection &amp; cyber</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1296px;\">Almost every business has commercially sensitive information, personal data or big datasets underpinning its assets, revenue and growth strategy. Our specialist data protection and cyber team has over 20 years' experience and is one of the biggest in Europe.</p>\n",
      "<h3 class=\"key-services__link-text\">Disputes &amp; investigations</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1296px;\">We represent global businesses and high net worth individuals on the successful resolution of complex and high-value commercial disputes and investigations. We work closely with our clients not only to resolve disputes – whether through litigation, arbitration or regulatory processes – but to proactively avoid them in the first place.</p>\n",
      "<h3 class=\"key-services__link-text\">Employment, pensions &amp; mobility</h3>\n",
      "<html><body><p>Employment, pensions &amp; mobility laws are all areas that have become increasingly topical and often are key to brand value. Our international network of lawyers will help guide you towards this future, and manage the impact of today’s employment, pensions and immigration legislation on your businesses.</p></body></html>\n",
      "<h3 class=\"key-services__link-text\">Intellectual property</h3>\n",
      "<h3 class=\"key-services__link-text\">Real estate &amp; construction</h3>\n",
      "<p class=\"equal-height-item--quarternary\" style=\"height: 1296px;\">We advise on all manner of real estate transactions, from high-profile acquisitions and disposals to pan European portfolios, to highly structured corporate transactions, to large scale development schemes, to the financing of all these and more.</p>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about_us_link=None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<div>\n",
      "<html><body><p>Our ability to understand people makes us who we are. We work together to build deep and trusted relationships that deliver meaningful value.</p></body></html>\n",
      "<html><body><p>Some of our clients</p></body></html>\n",
      "<h2 id=\"pc-title\">Cookie Preference Centre</h2>\n",
      "<h3 id=\"privacy-text\">Your Privacy</h3>\n",
      "<h3 id=\"privacy-text\">Your Privacy</h3>\n",
      "<p class=\"group-description\" id=\"pc-policy-text\">When you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.</p>\n",
      "<h3 id=\"ot-header-id-C0001\">Strictly Necessary Cookies</h3>\n",
      "<h3 id=\"ot-header-id-C0001\">Strictly Necessary Cookies</h3>\n",
      "<div class=\"ot-always-active\">Always Active</div>\n",
      "<h3 id=\"ot-header-id-C0001\">Strictly Necessary Cookies</h3>\n",
      "<p class=\"group-description ot-category-desc\">These cookies are necessary for the website to function and cannot be switched off in our systems. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.</p>\n",
      "<h3 id=\"ot-header-id-C0002\">Analytics Cookies</h3>\n",
      "<h3 id=\"ot-header-id-C0002\">Analytics Cookies</h3>\n",
      "<html><body><p>Allows us to recognize and count the number of users of our website and understand how you use it which helps us to improve how it works eg ensuring that you can find what you are looking for. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance. We use Google Analytics. To learn more about the use and choice of cookies for Google analytics, please visit the Google Analytics Opt-out Browser Add-on.</p></body></html>\n",
      "<h3 id=\"ot-header-id-C0003\">Functional Cookies</h3>\n",
      "<h3 id=\"ot-header-id-C0003\">Functional Cookies</h3>\n",
      "<p class=\"group-description ot-category-desc\">These cookies improve the functioning of the website and give you a better, more personal experience. They may be set by us or by third party providers whose services appear on our website. If you disable these cookies, some of the services may not function properly and your experience on the website is likely to be diminished.</p>\n",
      "<h3 id=\"ot-header-id-C0004\">Targeting/Marketing Cookies</h3>\n",
      "<h3 id=\"ot-header-id-C0004\">Targeting/Marketing Cookies</h3>\n",
      "<p class=\"group-description ot-category-desc\">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.</p>\n",
      "<h3 id=\"onetrust-policy-title\">Cookie consent</h3>\n",
      "<html><body><p>We use cookies which are essential for our website to work. We also use cookies to help us improve your experience which you can accept or reject here. You can change your mind at any time. For more information, see ourCookie notice.</p></body></html>\n",
      "</div>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about_us_link=None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Failed to fetch https://www.klgates.com/: Status code 500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Incoming markup is of an invalid type: None. Markup must be a string, a bytestring, or an open filehandle.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m relevant_link \u001b[38;5;129;01min\u001b[39;00m relevant_links.relevant_results:\n\u001b[32m      5\u001b[39m     html_content = scraper.scrape_html(relevant_link.link)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     clean_text, clean_html = \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclean_html_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(clean_html)\n\u001b[32m      9\u001b[39m     prompt = load_prompt(\u001b[33m\"\u001b[39m\u001b[33mgenerate_aboutus_link\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/tech_projects/growbal/scrapper.py:90\u001b[39m, in \u001b[36mHtmlScraper.clean_html_content\u001b[39m\u001b[34m(self, html_content, language)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_html_content\u001b[39m(\u001b[38;5;28mself\u001b[39m, html_content, language=\u001b[33m\"\u001b[39m\u001b[33mEnglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Remove unwanted elements\u001b[39;00m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m soup([\u001b[33m\"\u001b[39m\u001b[33mscript\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mheader\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfooter\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnav\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maside\u001b[39m\u001b[33m\"\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/bs4/__init__.py:442\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m     markup = markup.read()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[33m\"\u001b[39m\u001b[33m__len__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    443\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncoming markup is of an invalid type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmarkup\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Markup must be a string, a bytestring, or an open filehandle.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    444\u001b[39m     )\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) <= \u001b[32m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    446\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m    447\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m   (...)\u001b[39m\u001b[32m    451\u001b[39m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[32m    452\u001b[39m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._markup_is_url(markup):\n",
      "\u001b[31mTypeError\u001b[39m: Incoming markup is of an invalid type: None. Markup must be a string, a bytestring, or an open filehandle."
     ]
    }
   ],
   "source": [
    "for relevant_link in relevant_links.relevant_results:\n",
    "    html_content = scraper.scrape_html(relevant_link.link)\n",
    "    clean_text, clean_html = scraper.clean_html_content(html_content)\n",
    "    print(clean_html)\n",
    "\n",
    "    prompt = load_prompt(\"generate_about_us_link\")\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", prompt)\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(AboutUsOutput)\n",
    "    llm_chain = prompt_template | llm\n",
    "\n",
    "    result = llm_chain.invoke({\"html_content\": clean_html})\n",
    "    print(result)\n",
    "    print(result.about_us_link)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "    # filtered_links.append(links[int(relevant_result.id)][\"link\"])\n",
    "\n",
    "# print(filtered_links)\n",
    "    \n",
    "# print(links[int(relevant_links.relevant_results[0].id)][\"link\"])\n",
    "# print(relevant_links)\n",
    "# scrape_and_save_markdown(relevant_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scraper = HtmlScraper(scraping_api_key=os.environ[\"SCRAPING_API_KEY\"])\n",
    "html_strings = scraper.load_saved_html()\n",
    "for i, html_string in enumerate(html_strings):\n",
    "    clean_text, clean_html = scraper.clean_html_content(html_string)\n",
    "    html_strings[i] = clean_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-4 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_results=[ResultRelevance(explanation='This link is relevant because it is an international commercial law firm which is most likely to offer legal services.', id='2'), ResultRelevance(explanation='This link is relevant as it leads to a global law firm offering various legal services and also allows users to find a lawyer.', id='3'), ResultRelevance(explanation='This link is relevant as it leads to an international and offshore professional services firm with expertise to handle demanding and complex transactions, making it seem like a promising candidate for a legal service provider.', id='4'), ResultRelevance(explanation=\"This link is an official website for Thomson Reuters' legal resource center, making it relevant as Thomson Reuters is known for its legal services and resources.\", id='5'), ResultRelevance(explanation='The link appears to belong to an international law firm, indicating a likelihood of providing legal services and making it relevant.', id='7'), ResultRelevance(explanation=\"This link is relevant as it's an official webpage for a company (Lexitas) that provides legal staffing, document review and commercial contracts outsourcing services.\", id='9'), ResultRelevance(explanation=\"This link is relevant as it's the official website of a global law firm with more than 975 attorneys in multiple continents.\", id='10')]\n"
     ]
    }
   ],
   "source": [
    "prompt = load_prompt(\"generate_formal_site_link\")\n",
    "service = search_starters[3]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt)\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(AboutUsOutput)\n",
    "llm_chain = prompt_template | llm\n",
    "\n",
    "result = llm_chain.invoke({\"service\": service})\n",
    "\n",
    "print(\"prompt:\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n\")\n",
    "print(\"result:\\n\")\n",
    "print(result)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growbal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
