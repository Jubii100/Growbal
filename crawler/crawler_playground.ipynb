{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define your API endpoint and API key\n",
    "api_url = \"http://127.0.0.1:5000/v1/completions\"\n",
    "api_key = \"1cd8eaf71b54f5d12e64510bdbe0a008\"\n",
    "\n",
    "# Set up headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# Define your inference payload\n",
    "html_content = \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Innovatech Solutions Inc.</title>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>Innovatech Solutions Inc.</h1>\n",
    "        <p><strong>Category:</strong> Technology & Software Development</p>\n",
    "        <p><strong>Country of Origin:</strong> Canada</p>\n",
    "    </header>\n",
    "\n",
    "    <section id=\"description\">\n",
    "        <h2>About Us</h2>\n",
    "        <p>Innovatech Solutions specializes in custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.</p>\n",
    "    </section>\n",
    "\n",
    "    <section id=\"office-locations\">\n",
    "        <h2>Our Offices</h2>\n",
    "        <ul>\n",
    "            <li>Toronto, Canada</li>\n",
    "            <li>Vancouver, Canada</li>\n",
    "            <li>Berlin, Germany</li>\n",
    "        </ul>\n",
    "    </section>\n",
    "\n",
    "    <section id=\"staff\">\n",
    "        <h2>Meet Our Team</h2>\n",
    "        \n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Dr. Emily Porter</h3>\n",
    "            <p><strong>Position:</strong> Chief Technology Officer (CTO)</p>\n",
    "            <p><strong>Email:</strong> eporter@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +1-416-555-0145</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/emilyporter\">LinkedIn</a>,\n",
    "                <a href=\"https://twitter.com/emilyporter\">Twitter</a>\n",
    "            </p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Mark Reynolds</h3>\n",
    "            <p><strong>Position:</strong> Lead AI Engineer</p>\n",
    "            <p><strong>Email:</strong> mreynolds@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +1-604-555-0221</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/markreynolds\">LinkedIn</a>\n",
    "            </p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Sophia Khan</h3>\n",
    "            <p><strong>Position:</strong> Head of Digital Transformation</p>\n",
    "            <p><strong>Email:</strong> skhan@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +49-30-555-0877</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/sophiakhan\">LinkedIn</a>,\n",
    "                <a href=\"https://twitter.com/sophiakhan\">Twitter</a>,\n",
    "                <a href=\"https://instagram.com/sophiakhan\">Instagram</a>\n",
    "            </p>\n",
    "        </div>\n",
    "    </section>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "sql_schema = \"\"\"CREATE TABLE businesses (\n",
    "    business_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) UNIQUE NOT NULL,\n",
    "    description TEXT,\n",
    "    category VARCHAR(100),\n",
    "    country_of_origin VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE office_locations (\n",
    "    location_id SERIAL PRIMARY KEY,\n",
    "    business_id INTEGER REFERENCES businesses(business_id),\n",
    "    city VARCHAR(100),\n",
    "    country VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE staff (\n",
    "    staff_id SERIAL PRIMARY KEY,\n",
    "    business_id INTEGER REFERENCES businesses(business_id),\n",
    "    full_name VARCHAR(100),\n",
    "    position VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone VARCHAR(30)\n",
    ");\n",
    "\n",
    "CREATE TABLE staff_social_media (\n",
    "    social_id SERIAL PRIMARY KEY,\n",
    "    staff_id INTEGER REFERENCES staff(staff_id),\n",
    "    platform VARCHAR(50),\n",
    "    url VARCHAR(255)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# prompt = f\"\"\"You are tasked to meticulously analyze the provided HTML webpage content, identifying and extracting relevant business and professional staff details to create valid SQL insert commands.\\n\n",
    "# Extract precisely:\\n\n",
    "# Business name, description, category, country of origin.\\n\n",
    "# Each office location city and country.\\n\n",
    "# Each staff memberâ€™s name, position, email, phone, and social media accounts.\\n\n",
    "# Follow the given SQL schema strictly and only provide a ready-to-execute PostgreSQL command. Ensure accuracy and consistency; the command should execute correctly without modifications from the first attempt.\\n\n",
    "# Please provide only one executable PostgreSQL command. Nothing else.\\n\n",
    "# HTML Content:\\n\n",
    "# {html_content}\\n\n",
    "# SQL Schema:\\n\n",
    "# {sql_schema}\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are given HTML webpage content. Extract the details precisely:\n",
    "\n",
    "- Business name, description, category, country of origin.\n",
    "- Each office location city and country.\n",
    "- Staff member details: name, position, email, phone, and social media accounts.\n",
    "\n",
    "Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
    "\n",
    "{sql_schema}\n",
    "\n",
    "Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
    "\n",
    "Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
    "\n",
    "HTML Content:\n",
    "{html_content}\n",
    "\"\"\"\n",
    "\n",
    "# # print(prompt)\n",
    "# data = {\n",
    "#     \"prompt\": prompt,\n",
    "#     \"max_tokens\": 2048,\n",
    "#     \"temperature\": 0.1,\n",
    "#     \"top_p\": 0.8,\n",
    "#     \"top_k\": 20,\n",
    "#     \"frequency_penalty\": 0.05,\n",
    "#     \"presence_penalty\": 0.05,\n",
    "#     \"stream\": False\n",
    "# }\n",
    "\n",
    "# # Send POST request to the API\n",
    "# response = requests.post(api_url, headers=headers, json=data)\n",
    "\n",
    "# # Check and print the response\n",
    "# if response.status_code == 200:\n",
    "#     result = response.json()\n",
    "#     generated_text = result['choices'][0]['text']\n",
    "#     print(\"Generated Text:\\n\", generated_text)\n",
    "# else:\n",
    "#     print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "You are given HTML webpage content. Extract the details precisely:\n",
      "\n",
      "- Business name, description, category, country of origin.\n",
      "- Each office location city and country.\n",
      "- Staff member details: name, position, email, phone, and social media accounts.\n",
      "\n",
      "Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
      "\n",
      "CREATE TABLE businesses (\n",
      "    business_id SERIAL PRIMARY KEY,\n",
      "    name VARCHAR(255) UNIQUE NOT NULL,\n",
      "    description TEXT,\n",
      "    category VARCHAR(100),\n",
      "    country_of_origin VARCHAR(100)\n",
      ");\n",
      "\n",
      "CREATE TABLE office_locations (\n",
      "    location_id SERIAL PRIMARY KEY,\n",
      "    business_id INTEGER REFERENCES businesses(business_id),\n",
      "    city VARCHAR(100),\n",
      "    country VARCHAR(100)\n",
      ");\n",
      "\n",
      "CREATE TABLE staff (\n",
      "    staff_id SERIAL PRIMARY KEY,\n",
      "    business_id INTEGER REFERENCES businesses(business_id),\n",
      "    full_name VARCHAR(100),\n",
      "    position VARCHAR(100),\n",
      "    email VARCHAR(100),\n",
      "    phone VARCHAR(30)\n",
      ");\n",
      "\n",
      "CREATE TABLE staff_social_media (\n",
      "    social_id SERIAL PRIMARY KEY,\n",
      "    staff_id INTEGER REFERENCES staff(staff_id),\n",
      "    platform VARCHAR(50),\n",
      "    url VARCHAR(255)\n",
      ");\n",
      "\n",
      "\n",
      "Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
      "\n",
      "Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
      "\n",
      "HTML Content:\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Innovatech Solutions Inc.</title>\n",
      "</head>\n",
      "<body>\n",
      "    <header>\n",
      "        <h1>Innovatech Solutions Inc.</h1>\n",
      "        <p><strong>Category:</strong> Technology & Software Development</p>\n",
      "        <p><strong>Country of Origin:</strong> Canada</p>\n",
      "    </header>\n",
      "\n",
      "    <section id=\"description\">\n",
      "        <h2>About Us</h2>\n",
      "        <p>Innovatech Solutions specializes in custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.</p>\n",
      "    </section>\n",
      "\n",
      "    <section id=\"office-locations\">\n",
      "        <h2>Our Offices</h2>\n",
      "        <ul>\n",
      "            <li>Toronto, Canada</li>\n",
      "            <li>Vancouver, Canada</li>\n",
      "            <li>Berlin, Germany</li>\n",
      "        </ul>\n",
      "    </section>\n",
      "\n",
      "    <section id=\"staff\">\n",
      "        <h2>Meet Our Team</h2>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Dr. Emily Porter</h3>\n",
      "            <p><strong>Position:</strong> Chief Technology Officer (CTO)</p>\n",
      "            <p><strong>Email:</strong> eporter@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +1-416-555-0145</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/emilyporter\">LinkedIn</a>,\n",
      "                <a href=\"https://twitter.com/emilyporter\">Twitter</a>\n",
      "            </p>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Mark Reynolds</h3>\n",
      "            <p><strong>Position:</strong> Lead AI Engineer</p>\n",
      "            <p><strong>Email:</strong> mreynolds@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +1-604-555-0221</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/markreynolds\">LinkedIn</a>\n",
      "            </p>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Sophia Khan</h3>\n",
      "            <p><strong>Position:</strong> Head of Digital Transformation</p>\n",
      "            <p><strong>Email:</strong> skhan@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +49-30-555-0877</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/sophiakhan\">LinkedIn</a>,\n",
      "                <a href=\"https://twitter.com/sophiakhan\">Twitter</a>,\n",
      "                <a href=\"https://instagram.com/sophiakhan\">Instagram</a>\n",
      "            </p>\n",
      "        </div>\n",
      "    </section>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "Generated SQL: \n",
      "BEGIN;\n",
      "\n",
      "INSERT INTO businesses (name, description, category, country_of_origin) VALUES ('Innovatech Solutions Inc.', 'Custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.', 'Technology & Software Development', 'Canada');\n",
      "\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Toronto', 'Canada');\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Vancouver', 'Canada');\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Berlin', 'Germany');\n",
      "\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Dr. Emily Porter', 'Chief Technology Officer (CTO)', 'eporter@innovatech.ca', '+1-416-555-0145');\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Mark Reynolds', 'Lead AI Engineer', 'mreynolds@innovatech.ca', '+1-604-555-0221');\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Sophia Khan', 'Head of Digital Transformation', 'skhan@innovatech.ca', '+49-30-555-0877');\n",
      "\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Dr. Emily Porter'), 'LinkedIn', 'https://linkedin.com/in/emilyporter');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Dr. Emily Porter'), 'Twitter', 'https://twitter.com/emilyporter');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Mark Reynolds'), 'LinkedIn', 'https://linkedin.com/in/markreynolds');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'LinkedIn', 'https://linkedin.com/in/sophiakhan');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'Twitter', 'https://twitter.com/sophiakhan');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'Instagram', 'https://instagram.com/sophiakhan');\n",
      "\n",
      "COMMIT;\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Keep your singleton definition as it is\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "# Define your class for handling LLM interactions\n",
    "class LLMWrapper(metaclass=Singleton):\n",
    "    def __init__(self, config_file=\"ollama_config.json\"):\n",
    "        self.loaded = False\n",
    "        self.config_data = self.load_config(config_file)\n",
    "        self.load_response = self.load_model(self.config_data[\"LLM\"])\n",
    "        if self.load_response.status_code == 200:\n",
    "            self.loaded = True\n",
    "\n",
    "    def load_config(self, config_file):\n",
    "        with open(config_file, 'r') as f:\n",
    "            config_data = json.load(f)\n",
    "        for key, value in config_data.items():\n",
    "            os.environ[key] = str(value)\n",
    "        return config_data\n",
    "\n",
    "    def load_model(self, model_name: str):\n",
    "        url = self.config_data[\"LOAD_MODEL_API_PATH\"]\n",
    "        payload = {\"model\": model_name}\n",
    "        response = requests.post(url, json=payload)\n",
    "        return response\n",
    "\n",
    "    def run(self, prompt: str, chat=True):\n",
    "        if self.loaded:\n",
    "            url = self.config_data[\"CHAT_API_PATH\"] if chat else self.config_data[\"GENERATE_API_PATH\"]\n",
    "            payload = {\n",
    "                \"model\": self.config_data[\"LLM\"],\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": self.config_data[\"TEMPERATURE\"]}\n",
    "            }\n",
    "            response = requests.post(url, json=payload)\n",
    "            if response.ok:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Request failed: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Model not loaded.\")\n",
    "            return None\n",
    "\n",
    "# Example of using the above class\n",
    "llm = LLMWrapper()\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "response = llm.run(prompt)\n",
    "if response:\n",
    "    generated_sql = response['message']['content']\n",
    "    print(f\"Generated SQL: {generated_sql}\")\n",
    "else:\n",
    "    print(\"Failed to get response from LLM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"You are tasked to meticulously analyze the provided HTML webpage content, identifying and extracting relevant business and professional staff details to create valid SQL insert commands.\\n\n",
    "# Extract precisely:\\n\n",
    "# Business name, description, category, country of origin.\\n\n",
    "# Each office location city and country.\\n\n",
    "# Each staff memberâ€™s name, position, email, phone, and social media accounts.\\n\n",
    "# Follow the given SQL schema strictly and only provide a ready-to-execute PostgreSQL command. Ensure accuracy and consistency; the command should execute correctly without modifications from the first attempt.\\n\n",
    "# Please provide only one executable PostgreSQL command. Nothing else.\\n\n",
    "# HTML Content:\\n\n",
    "# {html_content}\\n\n",
    "# SQL Schema:\\n\n",
    "# {sql_schema}\"\"\"\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# You are given HTML webpage content. Extract the details precisely:\n",
    "\n",
    "# - Business name, description, category, country of origin.\n",
    "# - Each office location city and country.\n",
    "# - Staff member details: name, position, email, phone, and social media accounts.\n",
    "\n",
    "# Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
    "\n",
    "# {sql_schema}\n",
    "\n",
    "# Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
    "\n",
    "# Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
    "\n",
    "# HTML Content:\n",
    "# {html_content}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# You are given HTML content of a business webpage. Extract ONLY the following information precisely:\n",
    "\n",
    "# - Business Name\n",
    "# - Description\n",
    "# - Category\n",
    "# - Country of Origin\n",
    "# - Office Locations (City, Country)\n",
    "# - Staff Members:\n",
    "#     - Full Name\n",
    "#     - Position\n",
    "#     - Email\n",
    "#     - Phone\n",
    "#     - Social Media (platform and URLs)\n",
    "\n",
    "# Assume the PostgreSQL tables below are ALREADY CREATED, and DO NOT attempt to create them again:\n",
    "\n",
    "# {sql_schema}\n",
    "\n",
    "# Produce EXACTLY ONE PostgreSQL transaction (use BEGIN; ... COMMIT;) containing ONLY valid INSERT commands ready to execute directly in PostgreSQL. \n",
    "\n",
    "# Use PostgreSQL's RETURNING clause properly to retrieve generated primary keys for foreign key relations. Assume the use of variables (`business_id`, `staff_id`) for referencing foreign keys clearly.\n",
    "\n",
    "# Do NOT include Python, explanations, analysis, or any text except the executable SQL commands.\n",
    "\n",
    "# HTML Content:\n",
    "# {html_content}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# Extract the following from the given HTML:\n",
    "\n",
    "# - Business (name, description, category, country_of_origin)\n",
    "# - Office locations (city, country)\n",
    "# - Staff (full_name, position, email, phone)\n",
    "# - Staff social media (platform, url)\n",
    "\n",
    "# Generate ONLY PostgreSQL INSERT statements wrapped strictly within one transaction (BEGIN; ... COMMIT;) assuming the following schema already exists:\n",
    "\n",
    "# {sql_schema}\n",
    "\n",
    "# Strict instructions:\n",
    "# - NEVER write CREATE TABLE commands.\n",
    "# - Use RETURNING to get foreign keys.\n",
    "# - No placeholders; assume correct PostgreSQL syntax with variables.\n",
    "# - No explanations, code samples, HTML, Python, or analysisâ€”ONLY SQL commands.\n",
    "\n",
    "# HTML content:\n",
    "# {html_content}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 15:55:19 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 15:55:20,826\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 15:55:25 [config.py:717] This model supports multiple tasks: {'score', 'embed', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-03 15:55:25 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/anaconda3/envs/growbal/lib/python3.11/site-packages/vllm/transformers_utils/tokenizer_group.py:23: FutureWarning: It is strongly recommended to run mistral models with `--tokenizer-mode \"mistral\"` to ensure correct encoding and decoding.\n",
      "  self.tokenizer = get_tokenizer(self.tokenizer_id, **tokenizer_config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 15:55:26 [core.py:58] Initializing a V1 LLM engine (v0.8.5) with config: model='mistralai/Mistral-7B-v0.1', speculative_config=None, tokenizer='mistralai/Mistral-7B-v0.1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=mistralai/Mistral-7B-v0.1, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-03 15:55:26 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ed973d86f90>\n",
      "INFO 05-03 15:55:27 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-03 15:55:27 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-03 15:55:27 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-03 15:55:27 [gpu_model_runner.py:1329] Starting to load model mistralai/Mistral-7B-v0.1...\n",
      "INFO 05-03 15:55:31 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 05-03 16:00:24 [weight_utils.py:281] Time spent downloading weights for mistralai/Mistral-7B-v0.1: 292.479523 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.80s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.52s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.41s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 16:00:31 [loader.py:458] Loading weights took 6.94 seconds\n",
      "INFO 05-03 16:00:31 [gpu_model_runner.py:1347] Model loading took 9.4341 GiB and 304.282915 seconds\n",
      "INFO 05-03 16:00:35 [backends.py:420] Using cache directory: /home/mohammed/.cache/vllm/torch_compile_cache/f9c33428ba/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-03 16:00:35 [backends.py:430] Dynamo bytecode transform time: 3.25 s\n",
      "INFO 05-03 16:00:37 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 1.842 s\n",
      "INFO 05-03 16:00:37 [monitor.py:33] torch.compile takes 3.25 s in total\n",
      "INFO 05-03 16:03:52 [kv_cache_utils.py:634] GPU KV cache size: 37,152 tokens\n",
      "INFO 05-03 16:03:52 [kv_cache_utils.py:637] Maximum concurrency for 16,384 tokens per request: 2.27x\n",
      "INFO 05-03 16:12:10 [gpu_model_runner.py:1686] Graph capturing finished in 498 secs, took 0.51 GiB\n",
      "INFO 05-03 16:12:13 [core.py:159] init engine (profile, create kv cache, warmup model) took 701.77 seconds\n",
      "INFO 05-03 16:12:13 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "class SingletonLLM:\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = LLM(*args, **kwargs)\n",
    "        return cls._instance\n",
    "\n",
    "llm = SingletonLLM(\n",
    "    model=\"mistralai/Mistral-7B-v0.1\",\n",
    "    gpu_memory_utilization=0.97,\n",
    "    max_model_len=16384, # 12,288 words\n",
    "    max_num_seqs=2,\n",
    "    cpu_offload_gb=4,\n",
    "    swap_space=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vllm.entrypoints.llm.LLM'>\n",
      "<vllm.entrypoints.llm.LLM object at 0x7ed859199110>\n"
     ]
    }
   ],
   "source": [
    "print(type(llm))\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class LLMOutput(BaseModel):\n",
    "  content: str\n",
    "  stage: int\n",
    "\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "        \n",
    "class llm_wrap(metaclass=Singleton):\n",
    "    def __init__(self, config_file=\"ollama_config.json\"):\n",
    "        self.loaded = False\n",
    "        self.config_data = self.load_config(config_file)\n",
    "        self.load_response = self.load_model(self.config_data[\"LLM\"])\n",
    "        if self.load_response.status_code == 200: self.loaded = True\n",
    "        # self.output_schema = LLMOutput.model_json_schema()\n",
    "\n",
    "    def load_config(self, config_file):\n",
    "        with open(config_file, 'r') as f:\n",
    "            config_data = json.load(f)\n",
    "        for key, value in config_data.items():\n",
    "            os.environ[key] = str(value)\n",
    "        return config_data\n",
    "\n",
    "    def load_model(self, model_name: str):\n",
    "        url = self.config_data[\"LOAD_MODEL_API_PATH\"]\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"stream\": True \n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=payload)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def run(self, prompt: str, chat = True):\n",
    "        return self.process_prompt(prompt, chat)\n",
    "\n",
    "    def process_prompt(self, prompt: str, chat = True):\n",
    "        if self.loaded:\n",
    "            url = self.config_data[\"CHAT_API_PATH\"] if chat else self.config_data[\"GENERATE_API_PATH\"]\n",
    "            payload = {\n",
    "                        \"model\": self.config_data[\"LLM\"],\n",
    "                        \"messages\": prompt,\n",
    "                        # \"messages\": [\n",
    "                        #     {\n",
    "                        #     \"role\": \"user\",\n",
    "                        #     \"content\": prompt\n",
    "                        #     }\n",
    "                        # ],\n",
    "                        \"stream\": False,\n",
    "                        \"options\": {\n",
    "                                    \"temperature\": self.config_data[\"TEMPERATURE\"]\n",
    "                                    },\n",
    "                        # \"format\": self.output_schema\n",
    "                        }\n",
    "            response = requests.post(url, json=payload)\n",
    "\n",
    "            return response\n",
    "        else:\n",
    "            print(\"Failed to load the model\")\n",
    "            return False\n",
    "\n",
    "    # def process_prompt(self, prompt: str, chat = True):\n",
    "    #     if self.loaded:\n",
    "    #         url = self.config_data[\"CHAT_API_PATH\"] if chat else self.config_data[\"GENERATE_API_PATH\"]\n",
    "    #         payload = {\n",
    "    #                     \"model\": self.config_data[\"LLM\"],\n",
    "    #                     \"messages\": prompt,\n",
    "    #                     # \"messages\": [\n",
    "    #                     #     {\n",
    "    #                     #     \"role\": \"user\",\n",
    "    #                     #     \"content\": prompt\n",
    "    #                     #     }\n",
    "    #                     # ],\n",
    "    #                     \"stream\": True,\n",
    "    #                     \"options\": {\n",
    "    #                                 \"temperature\": self.config_data[\"TEMPERATURE\"]\n",
    "    #                                 },\n",
    "    #                     # \"format\": self.output_schema\n",
    "    #                     }\n",
    "    #         response = requests.post(url, json=payload, stream=True)\n",
    "    #         complete_message = \"\"\n",
    "    #         for line in response.iter_lines(decode_unicode=True):\n",
    "    #             if line:  \n",
    "    #                 try:\n",
    "    #                     chunk = json.loads(line)\n",
    "    #                     complete_message += chunk[\"message\"][\"content\"]\n",
    "    #                     yield complete_message\n",
    "    #                 except json.JSONDecodeError as e:\n",
    "    #                     print(\"Could not decode chunk:\", line)\n",
    "    #                     return False\n",
    "\n",
    "    #         # return response\n",
    "    #     else:\n",
    "    #         print(\"Failed to load the model\")\n",
    "    #         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class Singleton(type):\n",
    "#     _instances = {}\n",
    "#     def __call__(cls, *args, **kwargs):\n",
    "#         if cls not in cls._instances:\n",
    "#             cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "#         return cls._instances[cls]\n",
    "\n",
    "# class handle_prompt(metaclass=Singleton):\n",
    "#     def __init__(self, cache_size = 512):\n",
    "#         self.llm = llm_wrap()\n",
    "#         self.cache_size = cache_size\n",
    "\n",
    "#     def get_llm_output(self, prompt, chat = True):\n",
    "#         if len(self.cache) > self.cache_size:\n",
    "#             self.cache.popitem(last=False)\n",
    "\n",
    "#         self.embedding = embedding_wrap().run(prompt)\n",
    "#         if self.embedding: self.embedding = np.array(self.embedding)\n",
    "#         else: self.llm.run(prompt, chat = chat)\n",
    "\n",
    "#         self.embedding = self.process_embedding(self.embedding)\n",
    "#         if self.embedding in self.cache:\n",
    "#             self.cache.move_to_end(self.embedding)\n",
    "#             return [self.cache[self.embedding]]\n",
    "        \n",
    "#         return self.llm.run(prompt, chat = chat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\".env\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         key, value = line.strip().split(\"=\")\n",
    "#         os.environ[key] = value\n",
    "\n",
    "# llm_model = os.environ[\"LLM_VERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_serper(search_query):\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "        \"q\": search_query,\n",
    "        \"gl\": \"is\", \n",
    "        \"num\": 1,\n",
    "        \"tbs\": \"qdr:d\"\n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'X-API-KEY': os.environ[\"SERPER_API_KEY\"],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    results = json.loads(response.text)\n",
    "    results_list = results['organic']\n",
    "\n",
    "    all_results = []\n",
    "    for id, result in enumerate(results_list, 1):\n",
    "        result_dict = {\n",
    "            'title': result['title'],\n",
    "            'link': result['link'],\n",
    "            'snippet': result['snippet'],\n",
    "            'search_term': search_query,\n",
    "            'id': id\n",
    "        }\n",
    "        all_results.append(result_dict)\n",
    "    return all_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growbal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
