{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Innovatech Solutions Inc.</title>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>Innovatech Solutions Inc.</h1>\n",
    "        <p><strong>Category:</strong> Technology & Software Development</p>\n",
    "        <p><strong>Country of Origin:</strong> Canada</p>\n",
    "    </header>\n",
    "\n",
    "    <section id=\"description\">\n",
    "        <h2>About Us</h2>\n",
    "        <p>Innovatech Solutions specializes in custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.</p>\n",
    "    </section>\n",
    "\n",
    "    <section id=\"office-locations\">\n",
    "        <h2>Our Offices</h2>\n",
    "        <ul>\n",
    "            <li>Toronto, Canada</li>\n",
    "            <li>Vancouver, Canada</li>\n",
    "            <li>Berlin, Germany</li>\n",
    "        </ul>\n",
    "    </section>\n",
    "\n",
    "    <section id=\"staff\">\n",
    "        <h2>Meet Our Team</h2>\n",
    "        \n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Dr. Emily Porter</h3>\n",
    "            <p><strong>Position:</strong> Chief Technology Officer (CTO)</p>\n",
    "            <p><strong>Email:</strong> eporter@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +1-416-555-0145</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/emilyporter\">LinkedIn</a>,\n",
    "                <a href=\"https://twitter.com/emilyporter\">Twitter</a>\n",
    "            </p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Mark Reynolds</h3>\n",
    "            <p><strong>Position:</strong> Lead AI Engineer</p>\n",
    "            <p><strong>Email:</strong> mreynolds@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +1-604-555-0221</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/markreynolds\">LinkedIn</a>\n",
    "            </p>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"staff-member\">\n",
    "            <h3>Sophia Khan</h3>\n",
    "            <p><strong>Position:</strong> Head of Digital Transformation</p>\n",
    "            <p><strong>Email:</strong> skhan@innovatech.ca</p>\n",
    "            <p><strong>Phone:</strong> +49-30-555-0877</p>\n",
    "            <p><strong>Social Media:</strong>\n",
    "                <a href=\"https://linkedin.com/in/sophiakhan\">LinkedIn</a>,\n",
    "                <a href=\"https://twitter.com/sophiakhan\">Twitter</a>,\n",
    "                <a href=\"https://instagram.com/sophiakhan\">Instagram</a>\n",
    "            </p>\n",
    "        </div>\n",
    "    </section>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "sql_schema = \"\"\"CREATE TABLE businesses (\n",
    "    business_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) UNIQUE NOT NULL,\n",
    "    description TEXT,\n",
    "    category VARCHAR(100),\n",
    "    country_of_origin VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE office_locations (\n",
    "    location_id SERIAL PRIMARY KEY,\n",
    "    business_id INTEGER REFERENCES businesses(business_id),\n",
    "    city VARCHAR(100),\n",
    "    country VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE staff (\n",
    "    staff_id SERIAL PRIMARY KEY,\n",
    "    business_id INTEGER REFERENCES businesses(business_id),\n",
    "    full_name VARCHAR(100),\n",
    "    position VARCHAR(100),\n",
    "    email VARCHAR(100),\n",
    "    phone VARCHAR(30)\n",
    ");\n",
    "\n",
    "CREATE TABLE staff_social_media (\n",
    "    social_id SERIAL PRIMARY KEY,\n",
    "    staff_id INTEGER REFERENCES staff(staff_id),\n",
    "    platform VARCHAR(50),\n",
    "    url VARCHAR(255)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are given HTML webpage content. Extract the details precisely:\n",
    "\n",
    "- Business name, description, category, country of origin.\n",
    "- Each office location city and country.\n",
    "- Staff member details: name, position, email, phone, and social media accounts.\n",
    "\n",
    "Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
    "\n",
    "{sql_schema}\n",
    "\n",
    "Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
    "\n",
    "Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
    "\n",
    "HTML Content:\n",
    "{html_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "You are given HTML webpage content. Extract the details precisely:\n",
      "\n",
      "- Business name, description, category, country of origin.\n",
      "- Each office location city and country.\n",
      "- Staff member details: name, position, email, phone, and social media accounts.\n",
      "\n",
      "Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
      "\n",
      "CREATE TABLE businesses (\n",
      "    business_id SERIAL PRIMARY KEY,\n",
      "    name VARCHAR(255) UNIQUE NOT NULL,\n",
      "    description TEXT,\n",
      "    category VARCHAR(100),\n",
      "    country_of_origin VARCHAR(100)\n",
      ");\n",
      "\n",
      "CREATE TABLE office_locations (\n",
      "    location_id SERIAL PRIMARY KEY,\n",
      "    business_id INTEGER REFERENCES businesses(business_id),\n",
      "    city VARCHAR(100),\n",
      "    country VARCHAR(100)\n",
      ");\n",
      "\n",
      "CREATE TABLE staff (\n",
      "    staff_id SERIAL PRIMARY KEY,\n",
      "    business_id INTEGER REFERENCES businesses(business_id),\n",
      "    full_name VARCHAR(100),\n",
      "    position VARCHAR(100),\n",
      "    email VARCHAR(100),\n",
      "    phone VARCHAR(30)\n",
      ");\n",
      "\n",
      "CREATE TABLE staff_social_media (\n",
      "    social_id SERIAL PRIMARY KEY,\n",
      "    staff_id INTEGER REFERENCES staff(staff_id),\n",
      "    platform VARCHAR(50),\n",
      "    url VARCHAR(255)\n",
      ");\n",
      "\n",
      "\n",
      "Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
      "\n",
      "Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
      "\n",
      "HTML Content:\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Innovatech Solutions Inc.</title>\n",
      "</head>\n",
      "<body>\n",
      "    <header>\n",
      "        <h1>Innovatech Solutions Inc.</h1>\n",
      "        <p><strong>Category:</strong> Technology & Software Development</p>\n",
      "        <p><strong>Country of Origin:</strong> Canada</p>\n",
      "    </header>\n",
      "\n",
      "    <section id=\"description\">\n",
      "        <h2>About Us</h2>\n",
      "        <p>Innovatech Solutions specializes in custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.</p>\n",
      "    </section>\n",
      "\n",
      "    <section id=\"office-locations\">\n",
      "        <h2>Our Offices</h2>\n",
      "        <ul>\n",
      "            <li>Toronto, Canada</li>\n",
      "            <li>Vancouver, Canada</li>\n",
      "            <li>Berlin, Germany</li>\n",
      "        </ul>\n",
      "    </section>\n",
      "\n",
      "    <section id=\"staff\">\n",
      "        <h2>Meet Our Team</h2>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Dr. Emily Porter</h3>\n",
      "            <p><strong>Position:</strong> Chief Technology Officer (CTO)</p>\n",
      "            <p><strong>Email:</strong> eporter@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +1-416-555-0145</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/emilyporter\">LinkedIn</a>,\n",
      "                <a href=\"https://twitter.com/emilyporter\">Twitter</a>\n",
      "            </p>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Mark Reynolds</h3>\n",
      "            <p><strong>Position:</strong> Lead AI Engineer</p>\n",
      "            <p><strong>Email:</strong> mreynolds@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +1-604-555-0221</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/markreynolds\">LinkedIn</a>\n",
      "            </p>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"staff-member\">\n",
      "            <h3>Sophia Khan</h3>\n",
      "            <p><strong>Position:</strong> Head of Digital Transformation</p>\n",
      "            <p><strong>Email:</strong> skhan@innovatech.ca</p>\n",
      "            <p><strong>Phone:</strong> +49-30-555-0877</p>\n",
      "            <p><strong>Social Media:</strong>\n",
      "                <a href=\"https://linkedin.com/in/sophiakhan\">LinkedIn</a>,\n",
      "                <a href=\"https://twitter.com/sophiakhan\">Twitter</a>,\n",
      "                <a href=\"https://instagram.com/sophiakhan\">Instagram</a>\n",
      "            </p>\n",
      "        </div>\n",
      "    </section>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "Generated SQL: \n",
      "BEGIN;\n",
      "\n",
      "INSERT INTO businesses (name, description, category, country_of_origin) VALUES ('Innovatech Solutions Inc.', 'Custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.', 'Technology & Software Development', 'Canada');\n",
      "\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Toronto', 'Canada');\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Vancouver', 'Canada');\n",
      "INSERT INTO office_locations (business_id, city, country) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Berlin', 'Germany');\n",
      "\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Dr. Emily Porter', 'Chief Technology Officer (CTO)', 'eporter@innovatech.ca', '+1-416-555-0145');\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Mark Reynolds', 'Lead AI Engineer', 'mreynolds@innovatech.ca', '+1-604-555-0221');\n",
      "INSERT INTO staff (business_id, full_name, position, email, phone) VALUES ((SELECT business_id FROM businesses WHERE name = 'Innovatech Solutions Inc.'), 'Sophia Khan', 'Head of Digital Transformation', 'skhan@innovatech.ca', '+49-30-555-0877');\n",
      "\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Dr. Emily Porter'), 'LinkedIn', 'https://linkedin.com/in/emilyporter');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Dr. Emily Porter'), 'Twitter', 'https://twitter.com/emilyporter');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Mark Reynolds'), 'LinkedIn', 'https://linkedin.com/in/markreynolds');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'LinkedIn', 'https://linkedin.com/in/sophiakhan');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'Twitter', 'https://twitter.com/sophiakhan');\n",
      "INSERT INTO staff_social_media (staff_id, platform, url) VALUES ((SELECT staff_id FROM staff WHERE full_name = 'Sophia Khan'), 'Instagram', 'https://instagram.com/sophiakhan');\n",
      "\n",
      "COMMIT;\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "class LLMWrapper(metaclass=Singleton):\n",
    "    def __init__(self, config_file=\"ollama_config.json\"):\n",
    "        self.loaded = False\n",
    "        self.config_data = self.load_config(config_file)\n",
    "        self.load_response = self.load_model(self.config_data[\"LLM\"])\n",
    "        if self.load_response.status_code == 200:\n",
    "            self.loaded = True\n",
    "\n",
    "    def load_config(self, config_file):\n",
    "        with open(config_file, 'r') as f:\n",
    "            config_data = json.load(f)\n",
    "        for key, value in config_data.items():\n",
    "            os.environ[key] = str(value)\n",
    "        return config_data\n",
    "\n",
    "    def load_model(self, model_name: str):\n",
    "        url = self.config_data[\"LOAD_MODEL_API_PATH\"]\n",
    "        payload = {\"model\": model_name}\n",
    "        response = requests.post(url, json=payload)\n",
    "        return response\n",
    "\n",
    "    def run(self, prompt: str, chat=True):\n",
    "        if self.loaded:\n",
    "            url = self.config_data[\"CHAT_API_PATH\"] if chat else self.config_data[\"GENERATE_API_PATH\"]\n",
    "            payload = {\n",
    "                \"model\": self.config_data[\"LLM\"],\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": self.config_data[\"TEMPERATURE\"]}\n",
    "            }\n",
    "            response = requests.post(url, json=payload)\n",
    "            if response.ok:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Request failed: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Model not loaded.\")\n",
    "            return None\n",
    "\n",
    "llm = LLMWrapper()\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "response = llm.run(prompt)\n",
    "if response:\n",
    "    generated_sql = response['message']['content']\n",
    "    print(f\"Generated SQL: {generated_sql}\")\n",
    "else:\n",
    "    print(\"Failed to get response from LLM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_command=\"INSERT INTO businesses (name, description, category, country_of_origin) VALUES ('Innovatech Solutions Inc.', 'Custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.', 'Technology & Software Development', 'Canada');\"\n"
     ]
    }
   ],
   "source": [
    "from ollama_wrapper import ChatOllama\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_config(config_file=\"ollama_config.json\"):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    # for key, value in config_data.items():\n",
    "    #     os.environ[key] = str(value)\n",
    "    return config_data\n",
    "\n",
    "ollama_config_data = load_config()\n",
    "\n",
    "# Before refactor (using OpenAI Chat models):\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
    "# llm_summariser = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "# llm_reviewer = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "# After refactor (using local Ollama models via ChatOllama):\n",
    "\n",
    "# Initialize the main LLM (e.g., a larger model for primary tasks)\n",
    "sql_generator = ChatOllama(\n",
    "    model=ollama_config_data[\"LLM\"],            # name of the model as known to Ollama (e.g., \"llama2\" if pulled)\n",
    "    base_url=ollama_config_data[\"BASE_URL\"],\n",
    "    temperature=ollama_config_data[\"TEMPERATURE\"],\n",
    "    # max_tokens=1024 \n",
    ")\n",
    "\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define desired output schema as a Pydantic model\n",
    "class AnalysisResult(BaseModel):\n",
    "    sql_command: str\n",
    "\n",
    "# Wrap the LLM with structured output requirement\n",
    "structured_llm = sql_generator.with_structured_output(AnalysisResult)\n",
    "# Now use structured_llm in a chain or workflow:\n",
    "result = structured_llm.invoke(prompt)\n",
    "print(result)\n",
    "# -> AnalysisResult(summary=\"...something...\", sentiment=\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO businesses (name, description, category, country_of_origin) VALUES ('Innovatech Solutions Inc.', 'Innovatech Solutions specializes in custom software, AI integration, cloud solutions, and digital transformation services tailored for businesses aiming for accelerated growth and operational efficiency.', 'Technology & Software Development', 'Canada');\n"
     ]
    }
   ],
   "source": [
    "print(result.sql_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prompts/relevance_check.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m search_term \u001b[38;5;129;01min\u001b[39;00m search_terms:\n\u001b[32m    100\u001b[39m     python_results = search_serper(search_term)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     results = \u001b[43mcheck_search_relevance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     relevant_ids = [r.id \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results.relevant_results]\n\u001b[32m    105\u001b[39m     filtered_results = [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m python_results \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(r[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m relevant_ids]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mcheck_search_relevance\u001b[39m\u001b[34m(search_results)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_search_relevance\u001b[39m(search_results: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) -> RelevanceCheckOutput:\n\u001b[32m     76\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    Analyze search results and determine the most relevant ones.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \u001b[33;03m        RelevanceCheckOutput containing the most relevant results and explanation\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     prompt = \u001b[43mload_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelevance_check\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     prompt_template = ChatPromptTemplate.from_messages([\n\u001b[32m     88\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, prompt)\n\u001b[32m     89\u001b[39m     ])\n\u001b[32m     91\u001b[39m     llm = ChatOpenAI(openai_api_key=os.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m], model=llm_model).with_structured_output(RelevanceCheckOutput)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mload_prompt\u001b[39m\u001b[34m(prompt_name)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_prompt\u001b[39m(prompt_name):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompts/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.md\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     72\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m file.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'prompts/relevance_check.md'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "# from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import Field\n",
    "from typing import Literal\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from __future__ import print_function\n",
    "import sib_api_v3_sdk\n",
    "from sib_api_v3_sdk.rest import ApiException\n",
    "from IPython.display import display\n",
    "\n",
    "llm_model = os.environ[\"LLM_VERSION\"]\n",
    "\n",
    "search_terms = [\"recent phylosophical trends\", \"new cognitive bias study\", \"recent studies on intelligence\", \"New Reinforcement Learning\", \"Reinforcement Learning LinkedIn\", \"Agentic Reinforcement\"]\n",
    "\n",
    "class ResultRelevance(BaseModel):\n",
    "    explanation: str\n",
    "    id: str\n",
    "\n",
    "class RelevanceCheckOutput(BaseModel):\n",
    "    relevant_results: List[ResultRelevance]\n",
    "    \n",
    "\n",
    "def search_serper(search_query):\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    \n",
    "    payload = json.dumps({\n",
    "        \"q\": search_query,\n",
    "        \"gl\": \"ae\", \n",
    "        \"num\": 4,\n",
    "        \"tbs\": \"qdr:d\"\n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'X-API-KEY': os.environ[\"SERPER_API_KEY\"],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    results = json.loads(response.text)\n",
    "    results_list = results['organic']\n",
    "\n",
    "    all_results = []\n",
    "    for id, result in enumerate(results_list, 1):\n",
    "        result_dict = {\n",
    "            'title': result['title'],\n",
    "            'link': result['link'],\n",
    "            'snippet': result['snippet'],\n",
    "            'search_term': search_query,\n",
    "            'id': id\n",
    "        }\n",
    "        all_results.append(result_dict)\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def load_prompt(prompt_name):\n",
    "    with open(f\"prompts/{prompt_name}.md\", \"r\") as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def check_search_relevance(search_results: Dict[str, Any]) -> RelevanceCheckOutput:\n",
    "    \"\"\"\n",
    "    Analyze search results and determine the most relevant ones.\n",
    "    \n",
    "    Args:\n",
    "        search_results: Dictionary containing search results to analyze\n",
    "        \n",
    "    Returns:\n",
    "        RelevanceCheckOutput containing the most relevant results and explanation\n",
    "    \"\"\"\n",
    "    prompt = load_prompt(\"relevance_check\")\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", prompt)\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model).with_structured_output(RelevanceCheckOutput)\n",
    "    llm_chain = prompt_template | llm\n",
    "    \n",
    "    return llm_chain.invoke({\"search_terms\": search_terms, 'search_results': search_results})\n",
    "\n",
    "\n",
    "\n",
    "relevant_results = []\n",
    "for search_term in search_terms:\n",
    "    python_results = search_serper(search_term)\n",
    "    results = check_search_relevance(python_results)\n",
    "    \n",
    "    relevant_ids = [r.id for r in results.relevant_results]\n",
    "    \n",
    "    filtered_results = [r for r in python_results if str(r['id']) in relevant_ids]\n",
    "    \n",
    "    relevant_results.extend(filtered_results)\n",
    "  \n",
    "\n",
    "\n",
    "def convert_html_to_markdown(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Headers\n",
    "    for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        level = int(h.name[1])\n",
    "        h.replace_with('#' * level + ' ' + h.get_text() + '\\n\\n')\n",
    "    \n",
    "    # Links\n",
    "    for a in soup.find_all('a'):\n",
    "        href = a.get('href', '')\n",
    "        text = a.get_text()\n",
    "        if href and text:\n",
    "            a.replace_with(f'[{text}]({href})')\n",
    "    \n",
    "    # Bold\n",
    "    for b in soup.find_all(['b', 'strong']):\n",
    "        b.replace_with(f'**{b.get_text()}**')\n",
    "    \n",
    "    # Italic\n",
    "    for i in soup.find_all(['i', 'em']):\n",
    "        i.replace_with(f'*{i.get_text()}*')\n",
    "    \n",
    "    # Lists\n",
    "    for ul in soup.find_all('ul'):\n",
    "        for li in ul.find_all('li'):\n",
    "            li.replace_with(f'- {li.get_text()}\\n')\n",
    "    \n",
    "    for ol in soup.find_all('ol'):\n",
    "        for i, li in enumerate(ol.find_all('li'), 1):\n",
    "            li.replace_with(f'{i}. {li.get_text()}\\n')\n",
    "    \n",
    "    # Get text and clean up\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Remove excess whitespace/newlines\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def scrape_and_save_markdown(relevant_results):\n",
    "    \"\"\"\n",
    "    Scrapes HTML content from URLs in relevant_results and saves as markdown files.\n",
    "    \n",
    "    Args:\n",
    "        relevant_results: List of dictionaries containing search results with URLs\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing markdown content and metadata\n",
    "    \"\"\"\n",
    "    # Create scraped_html directory if it doesn't exist\n",
    "    # pathlib.Path(\"scraped_markdown\").mkdir(exist_ok=True)\n",
    "\n",
    "    markdown_contents = []\n",
    "    for result in relevant_results:\n",
    "        if 'link' in result:\n",
    "            payload = {\n",
    "                \"api_key\": os.environ[\"SCRAPING_API_KEY\"], \n",
    "                \"url\": result['link'],\n",
    "                \"render_js\": \"true\"\n",
    "            }\n",
    "\n",
    "            response = requests.get(\"https://scraping.narf.ai/api/v1/\", params=payload)\n",
    "            if response.status_code == 200:\n",
    "                # Create filename from ID or URL if ID not available\n",
    "                # filename = f\"{result.get('id', hash(result['link']))}.md\"\n",
    "                # filepath = os.path.join(\"scraped_markdown\", filename)\n",
    "                \n",
    "                # Convert HTML to markdown\n",
    "                markdown_content = convert_html_to_markdown(response.content.decode())\n",
    "                \n",
    "                # Save markdown content to file\n",
    "                # with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                #     f.write(markdown_content)\n",
    "                \n",
    "                markdown_contents.append({\n",
    "                    'url': result['link'],\n",
    "                    # 'filepath': filepath,\n",
    "                    'markdown': markdown_content,\n",
    "                    'title': result.get('title', ''),\n",
    "                    'id': result.get('id', '')\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Failed to fetch {result['link']}: Status code {response.status_code}\")\n",
    "\n",
    "    # print(f\"Successfully downloaded and saved {len(markdown_contents)} pages as markdown to scraped_markdown/\")\n",
    "    print(f\"Successfully downloaded and saved {len(markdown_contents)} pages as markdown\")\n",
    "    return markdown_contents\n",
    "\n",
    "markdown_contents = scrape_and_save_markdown(relevant_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\".env\", \"r\") as f:\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(\"=\")\n",
    "        os.environ[key] = value\n",
    "\n",
    "relevant_results = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"title\": \"Raalc About\",\n",
    "        \"link\": \"https://www.raalc.ae/about\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"title\": \"Hadef Partners About\",\n",
    "        \"link\": \"https://hadefpartners.com/about-us/who-we-are/\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"title\": \"The Firm Dubai About\",\n",
    "        \"link\": \"https://www.thefirmdubai.com/about#AboutUs\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"4\",\n",
    "        \"title\": \"Davidson Colaw About\",\n",
    "        \"link\": \"https://davidsoncolaw.com/about-us/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# # Saving HTML pages locally\n",
    "# def scrape_and_save_html(relevant_results, directory=\"saved_html\"):\n",
    "#     os.makedirs(directory, exist_ok=True)\n",
    "#     saved_files = []\n",
    "\n",
    "#     for result in relevant_results:\n",
    "#         if 'link' in result:\n",
    "#             payload = {\n",
    "#                 \"api_key\": os.environ[\"SCRAPING_API_KEY\"], \n",
    "#                 \"url\": result['link'],\n",
    "#                 \"render_js\": \"true\"\n",
    "#             }\n",
    "\n",
    "#             response = requests.get(\"https://scraping.narf.ai/api/v1/\", params=payload)\n",
    "#             if response.status_code == 200:\n",
    "#                 filename = f\"{result.get('id', hash(result['link']))}.html\"\n",
    "#                 filepath = os.path.join(directory, filename)\n",
    "#                 with open(filepath, 'w', encoding='utf-8') as file:\n",
    "#                     file.write(response.content.decode())\n",
    "#                 saved_files.append(filepath)\n",
    "#             else:\n",
    "#                 print(f\"Failed to fetch {result['link']}: Status code {response.status_code}\")\n",
    "\n",
    "#     print(f\"Successfully downloaded and saved {len(saved_files)} pages as HTML to '{directory}'/\")\n",
    "#     return saved_files\n",
    "\n",
    "# # Loading HTML pages back as string objects\n",
    "# def load_saved_html(filepaths):\n",
    "#     html_strings = []\n",
    "\n",
    "#     for filepath in filepaths:\n",
    "#         with open(filepath, 'r', encoding='utf-8') as file:\n",
    "#             html_strings.append(file.read())\n",
    "\n",
    "#     print(f\"Successfully loaded {len(html_strings)} HTML pages into strings\")\n",
    "#     return html_strings\n",
    "\n",
    "# # Example usage:\n",
    "# saved_file_paths = scrape_and_save_html(relevant_results)\n",
    "# loaded_html_strings = load_saved_html(saved_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Content preview of HTML file 1 ---\n",
      "<!DOCTYPE html><html class=\"no-js\" lang=\"en\" dir=\"ltr\"><head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Hadef &amp; Partners - A leading independent UAE law firm</title>\n",
      "    <meta name=\"viewport\" content=...\n",
      "\n",
      "--- Content preview of HTML file 2 ---\n",
      "<!DOCTYPE html><html><head><meta charset=\"utf-8\"><script>if(navigator.userAgent.match(/MSIE|Internet Explorer/i)||navigator.userAgent.match(/Trident\\/7\\..*?rv:11/i)){var href=document.location.href;if...\n",
      "\n",
      "--- Content preview of HTML file 3 ---\n",
      "<!DOCTYPE html><html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" class=\"pointer skrollr skrollr-desktop\"><head>\n",
      "    <style id=\"customRules\"></style><meta charset=\"utf-8\">\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "--- Content preview of HTML file 4 ---\n",
      "<!DOCTYPE html><html lang=\"en\" class=\"lenis lenis-smooth\"><head><style data-rc-order=\"prependQueue\" data-rc-priority=\"-999\" data-css-hash=\"1mqvjt9\" data-token-hash=\"fkne30\">:where(.css-m4timi) a{color...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# def load_saved_html(directory_path):\n",
    "#     html_files = glob.glob(os.path.join(directory_path, \"*.html\"))\n",
    "#     loaded_html_strings = []\n",
    "#     for file_path in html_files:\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             loaded_html_strings.append(file.read())\n",
    "#     return loaded_html_strings\n",
    "\n",
    "# # Example usage:\n",
    "# directory_path = '/home/mohammed/Desktop/tech_projects/growbal/saved_html'\n",
    "\n",
    "# loaded_html_strings = load_saved_html(directory_path)\n",
    "\n",
    "# # Example of printing a preview of each HTML file content\n",
    "# for idx, content in enumerate(loaded_html_strings, start=1):\n",
    "#     print(f\"--- Content preview of HTML file {idx} ---\\n{content[:200]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text Content:\\n RAALC - Tradition of excellence\n",
      "\n",
      "RAALC’s journey began in 2013, when it was co-founded in the Emirate of Sharjah. Our success continued through years and we opened our two newbranches in Ras Al Khaimah and Dubai, which in 2018, became our headquarter.\n",
      "The tradition of excellence recognised and intended by the founders continues to this very day. RAALC has cultivated a fantastic reputation for excellence over a collective experience of 30 years. Our core determination is creating partnerships that engross the clients in a peaceful mind where we take care of the zealous representation and expert advice.\n",
      "We started out with core litigation practice, and after that, it grew to encompass the umbrella of experience, such as corporate, commercial, banking and finance, restructuring and restructuring of business, exit strategy, and the list goes on.\n",
      "\n",
      "We seek to become UAE’s first smart-law firm!\n",
      "\n",
      "We carry the long-standing tradition of excellence with experience and innovation in the legal practice together with community leadership and skills for addressing the clients’ concerns.\n",
      "RAALC endeavours on a future perspective of intending on spanning globally in international jurisdictions, with revolutionary operations. We create long lasting connections with legal professionals from round the globe.\n",
      "We have noticed a remarkable growth in the blockchain industry and artificial intelligence (AI) and we are putting it to thrive in our mechanisms. We envision our company as a smart-law firm that is focused on creating amazing client experiences, adopting a culture of change and using technology to empower greater efficiency.\n",
      "We seek to become UAE’s first smart-law firm!\n",
      "With the everlasting standing in the industry, RAALC strives to continue to grow in the legal field.\n",
      "\n",
      "Integrity. Advocacy. Success\n",
      "\n",
      "Integrity. Advocacy. Success\n",
      "\n",
      "Company History\n",
      "\n",
      "2013\n",
      "\n",
      "FOUNDATION\n",
      "\n",
      "RAALC Law Firm established its presence in the UAE with its first office in Sharjah. This marked the beginning of our journey to provide exceptional legal services in the region.\n",
      "\n",
      "2015\n",
      "\n",
      "EXPANSION\n",
      "\n",
      "In 2015, RAALC expanded its reach by opening a new office in Dubai, followed by another branch in Ras Al Khaimah. This strategic expansion allowed us to better serve our clients across different emirates.\n",
      "\n",
      "2015\n",
      "\n",
      "DIVERSITY\n",
      "\n",
      "RAALC diversified its services by establishing specialized departments to handle specific legal areas. This comprehensive legal approach enabled us to cater to a wide range of client needs with expertise and precision.\n",
      "\n",
      "2016\n",
      "\n",
      "HEADQUATERS\n",
      "\n",
      "In 2016, RAALC designated its Dubai office as the headquarters. This centralization facilitated improved coordination and delivery of our legal services across all branches.\n",
      "\n",
      "2017\n",
      "\n",
      "GROWTH\n",
      "\n",
      "RAALC experienced significant growth in 2017, welcoming new associates and lawyers to our team. These professionals brought with them global experience and multilingual expertise, enhancing our ability to serve a diverse clientele.\n",
      "\n",
      "2018\n",
      "\n",
      "CORPORATE FOCUS\n",
      "\n",
      "By 2018, RAALC shifted its focus exclusively to major corporate entities within the UAE and internationally. This strategic decision allowed us to leverage our expertise to meet the complex legal needs of large organizations.\n",
      "\n",
      "2018\n",
      "\n",
      "SMART LAW FIRM\n",
      "\n",
      "In the same year, RAALC embraced technological innovation by integrating AI into our legal operations. This advancement enabled us to provide personalized customer service built on smart technology, improving efficiency and client satisfaction.\n",
      "\n",
      "2020\n",
      "\n",
      "GLOBAL EXPANSION\n",
      "\n",
      "With more than 30 years of combined experience, RAALC continued to expand globally in 2020. We formed strategic partnerships that allowed us to offer clients peace of mind through zealous representation and expert legal advice.\n",
      "\n",
      "2024\n",
      "\n",
      "NEW JOURNEY\n",
      "\n",
      "In 2024, RAALC embarked on a new journey by relocating its headquarters to the Dubai Supreme Courts building. This move symbolizes our commitment to being at the heart of the legal community and continuing to deliver top-tier legal services.\n",
      "\n",
      "TECHNOLOGY DRIVEN\n",
      "\n",
      "In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.\n",
      "\n",
      "DIVERSE\n",
      "\n",
      "Diversity is our core aspect of what we are and how we work - RAALC Law Firm devolves on the principles of inclusion and diversity. It portrays a varied reflection of our society where we promote leadership and individuals.\n",
      "\n",
      "VALUE DRIVEN\n",
      "\n",
      "RAALC pledges to abide by the core values within the organization, since its foundation. The core values embraced by RAALC promotes the achievement of the business aims and forms a correct culture. We carve out unconventional and ground breaking business ideas and work towards accomplishing client gratification with the intention that they will surge with a value-driven business. Our core values lie in embodying diversity and inclusion, genuinely with our operations and philanthropy.\n",
      "\n",
      "COMPREHENSIVE APPROACH OF LEGAL SERVICES\n",
      "\n",
      "Our perspective to the point and question of law takes a turn with employing a comprehensive approach by incorporating the industry-specific and based know-how that is built over the years.\n",
      "\n",
      "AGILE AND RESPONSIVENESS\n",
      "\n",
      "Since the time of its inception, RAALC it is encountering a superior transformation in the manner that it desires a perfect stability of balance and a dynamic nature. RAALC is agile in its work and quick responders.\n",
      "\n",
      "TECHNOLOGY DRIVEN\n",
      "\n",
      "In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.\n",
      "\n",
      "01\n",
      "\n",
      "TECHNOLOGY DRIVEN\n",
      "\n",
      "DIVERSE\n",
      "\n",
      "Diversity is our core aspect of what we are and how we work - RAALC Law Firm devolves on the principles of inclusion and diversity. It portrays a varied reflection of our society where we promote leadership and individuals.\n",
      "\n",
      "02\n",
      "\n",
      "DIVERSE\n",
      "\n",
      "VALUE DRIVEN\n",
      "\n",
      "RAALC pledges to abide by the core values within the organization, since its foundation. The core values embraced by RAALC promotes the achievement of the business aims and forms a correct culture. We carve out unconventional and ground breaking business ideas and work towards accomplishing client gratification with the intention that they will surge with a value-driven business. Our core values lie in embodying diversity and inclusion, genuinely with our operations and philanthropy.\n",
      "\n",
      "03\n",
      "\n",
      "VALUE DRIVEN\n",
      "\n",
      "COMPREHENSIVE APPROACH OF LEGAL SERVICES\n",
      "\n",
      "Our perspective to the point and question of law takes a turn with employing a comprehensive approach by incorporating the industry-specific and based know-how that is built over the years.\n",
      "\n",
      "04\n",
      "\n",
      "COMPREHENSIVE APPROACH OF LEGAL SERVICES\n",
      "\n",
      "AGILE AND RESPONSIVENESS\n",
      "\n",
      "Since the time of its inception, RAALC it is encountering a superior transformation in the manner that it desires a perfect stability of balance and a dynamic nature. RAALC is agile in its work and quick responders.\n",
      "\n",
      "05\n",
      "\n",
      "AGILE AND RESPONSIVENESS\n",
      "\n",
      "Memberships & Partnerships\n",
      "\n",
      "RAALC Law Firm is proud to be affiliated with numerous prestigious organizations and institutions. Our memberships and partnerships reflect our commitment to excellence, innovation, and collaboration in the legal field. By aligning with leading industry bodies, we ensure that our clients benefit from the latest legal insights and best practices. Our strategic partnerships also enable us to offer comprehensive legal solutions, leveraging a global network of expertise.\n",
      "\n",
      "TECHNOLOGY DRIVEN\n",
      "\n",
      "MEETING BOOKING SYSTEM\n",
      "\n",
      "ARTIFICIAL INTELLIGENCE\n",
      "\n",
      "CUSTOMER RELATIONSHIP MANAGEMENT\n",
      "\n",
      "RAALC APP\n",
      "\n",
      "In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.\n",
      "Cleaned HTML Content:\\n <div>\n",
      "<p>RAALC - Tradition of excellence</p>\n",
      "<p>RAALC’s journey began in 2013, when it was co-founded in the Emirate of Sharjah. Our success continued through years and we opened our two newbranches in Ras Al Khaimah and Dubai, which in 2018, became our headquarter.\n",
      "The tradition of excellence recognised and intended by the founders continues to this very day. RAALC has cultivated a fantastic reputation for excellence over a collective experience of 30 years. Our core determination is creating partnerships that engross the clients in a peaceful mind where we take care of the zealous representation and expert advice.\n",
      "We started out with core litigation practice, and after that, it grew to encompass the umbrella of experience, such as corporate, commercial, banking and finance, restructuring and restructuring of business, exit strategy, and the list goes on.</p>\n",
      "<p>We seek to become UAE’s first smart-law firm!</p>\n",
      "<p>We carry the long-standing tradition of excellence with experience and innovation in the legal practice together with community leadership and skills for addressing the clients’ concerns.\n",
      "RAALC endeavours on a future perspective of intending on spanning globally in international jurisdictions, with revolutionary operations. We create long lasting connections with legal professionals from round the globe.\n",
      "We have noticed a remarkable growth in the blockchain industry and artificial intelligence (AI) and we are putting it to thrive in our mechanisms. We envision our company as a smart-law firm that is focused on creating amazing client experiences, adopting a culture of change and using technology to empower greater efficiency.\n",
      "We seek to become UAE’s first smart-law firm!\n",
      "With the everlasting standing in the industry, RAALC strives to continue to grow in the legal field.</p>\n",
      "<p>Integrity. Advocacy. Success</p>\n",
      "<p>Integrity. Advocacy. Success</p>\n",
      "<p>Company History</p>\n",
      "<p>2013</p>\n",
      "<p>FOUNDATION</p>\n",
      "<p>RAALC Law Firm established its presence in the UAE with its first office in Sharjah. This marked the beginning of our journey to provide exceptional legal services in the region.</p>\n",
      "<p>2015</p>\n",
      "<p>EXPANSION</p>\n",
      "<p>In 2015, RAALC expanded its reach by opening a new office in Dubai, followed by another branch in Ras Al Khaimah. This strategic expansion allowed us to better serve our clients across different emirates.</p>\n",
      "<p>2015</p>\n",
      "<p>DIVERSITY</p>\n",
      "<p>RAALC diversified its services by establishing specialized departments to handle specific legal areas. This comprehensive legal approach enabled us to cater to a wide range of client needs with expertise and precision.</p>\n",
      "<p>2016</p>\n",
      "<p>HEADQUATERS</p>\n",
      "<p>In 2016, RAALC designated its Dubai office as the headquarters. This centralization facilitated improved coordination and delivery of our legal services across all branches.</p>\n",
      "<p>2017</p>\n",
      "<p>GROWTH</p>\n",
      "<p>RAALC experienced significant growth in 2017, welcoming new associates and lawyers to our team. These professionals brought with them global experience and multilingual expertise, enhancing our ability to serve a diverse clientele.</p>\n",
      "<p>2018</p>\n",
      "<p>CORPORATE FOCUS</p>\n",
      "<p>By 2018, RAALC shifted its focus exclusively to major corporate entities within the UAE and internationally. This strategic decision allowed us to leverage our expertise to meet the complex legal needs of large organizations.</p>\n",
      "<p>2018</p>\n",
      "<p>SMART LAW FIRM</p>\n",
      "<p>In the same year, RAALC embraced technological innovation by integrating AI into our legal operations. This advancement enabled us to provide personalized customer service built on smart technology, improving efficiency and client satisfaction.</p>\n",
      "<p>2020</p>\n",
      "<p>GLOBAL EXPANSION</p>\n",
      "<p>With more than 30 years of combined experience, RAALC continued to expand globally in 2020. We formed strategic partnerships that allowed us to offer clients peace of mind through zealous representation and expert legal advice.</p>\n",
      "<p>2024</p>\n",
      "<p>NEW JOURNEY</p>\n",
      "<p>In 2024, RAALC embarked on a new journey by relocating its headquarters to the Dubai Supreme Courts building. This move symbolizes our commitment to being at the heart of the legal community and continuing to deliver top-tier legal services.</p>\n",
      "<p>TECHNOLOGY DRIVEN</p>\n",
      "<p>In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.</p>\n",
      "<p>DIVERSE</p>\n",
      "<p>Diversity is our core aspect of what we are and how we work - RAALC Law Firm devolves on the principles of inclusion and diversity. It portrays a varied reflection of our society where we promote leadership and individuals.</p>\n",
      "<p>VALUE DRIVEN</p>\n",
      "<p>RAALC pledges to abide by the core values within the organization, since its foundation. The core values embraced by RAALC promotes the achievement of the business aims and forms a correct culture. We carve out unconventional and ground breaking business ideas and work towards accomplishing client gratification with the intention that they will surge with a value-driven business. Our core values lie in embodying diversity and inclusion, genuinely with our operations and philanthropy.</p>\n",
      "<p>COMPREHENSIVE APPROACH OF LEGAL SERVICES</p>\n",
      "<p>Our perspective to the point and question of law takes a turn with employing a comprehensive approach by incorporating the industry-specific and based know-how that is built over the years.</p>\n",
      "<p>AGILE AND RESPONSIVENESS</p>\n",
      "<p>Since the time of its inception, RAALC it is encountering a superior transformation in the manner that it desires a perfect stability of balance and a dynamic nature. RAALC is agile in its work and quick responders.</p>\n",
      "<p>TECHNOLOGY DRIVEN</p>\n",
      "<p>In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.</p>\n",
      "<p>01</p>\n",
      "<p>TECHNOLOGY DRIVEN</p>\n",
      "<p>DIVERSE</p>\n",
      "<p>Diversity is our core aspect of what we are and how we work - RAALC Law Firm devolves on the principles of inclusion and diversity. It portrays a varied reflection of our society where we promote leadership and individuals.</p>\n",
      "<p>02</p>\n",
      "<p>DIVERSE</p>\n",
      "<p>VALUE DRIVEN</p>\n",
      "<p>RAALC pledges to abide by the core values within the organization, since its foundation. The core values embraced by RAALC promotes the achievement of the business aims and forms a correct culture. We carve out unconventional and ground breaking business ideas and work towards accomplishing client gratification with the intention that they will surge with a value-driven business. Our core values lie in embodying diversity and inclusion, genuinely with our operations and philanthropy.</p>\n",
      "<p>03</p>\n",
      "<p>VALUE DRIVEN</p>\n",
      "<p>COMPREHENSIVE APPROACH OF LEGAL SERVICES</p>\n",
      "<p>Our perspective to the point and question of law takes a turn with employing a comprehensive approach by incorporating the industry-specific and based know-how that is built over the years.</p>\n",
      "<p>04</p>\n",
      "<p>COMPREHENSIVE APPROACH OF LEGAL SERVICES</p>\n",
      "<p>AGILE AND RESPONSIVENESS</p>\n",
      "<p>Since the time of its inception, RAALC it is encountering a superior transformation in the manner that it desires a perfect stability of balance and a dynamic nature. RAALC is agile in its work and quick responders.</p>\n",
      "<p>05</p>\n",
      "<p>AGILE AND RESPONSIVENESS</p>\n",
      "<p>Memberships & Partnerships</p>\n",
      "<p>RAALC Law Firm is proud to be affiliated with numerous prestigious organizations and institutions. Our memberships and partnerships reflect our commitment to excellence, innovation, and collaboration in the legal field. By aligning with leading industry bodies, we ensure that our clients benefit from the latest legal insights and best practices. Our strategic partnerships also enable us to offer comprehensive legal solutions, leveraging a global network of expertise.</p>\n",
      "<p>TECHNOLOGY DRIVEN</p>\n",
      "<p>MEETING BOOKING SYSTEM</p>\n",
      "<p>ARTIFICIAL INTELLIGENCE</p>\n",
      "<p>CUSTOMER RELATIONSHIP MANAGEMENT</p>\n",
      "<p>RAALC APP</p>\n",
      "<p>In the digital technology era, RAALC believes that it should be accessible to its clientele at a moment’s notice. It is determined to provide personalized customer service built on smart technology.</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import justext\n",
    "\n",
    "# html_content = loaded_html_strings[3]\n",
    "\n",
    "# # 2. Parse the HTML content with BeautifulSoup (using lxml parser for robustness)\n",
    "# soup = BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "# # 3. Remove unwanted elements by tag name (scripts, styles, navbars, footers, etc.)\n",
    "# for tag in soup([\"script\", \"style\"]):\n",
    "#     tag.decompose()  # remove script and style entirely\n",
    "# for tag in soup([\"header\", \"footer\", \"nav\", \"aside\"]):\n",
    "#     tag.decompose()  # remove common layout sections like header, footer, nav, sidebar\n",
    "\n",
    "# # Optionally, remove elements by specific class or id patterns (e.g., ads or banners)\n",
    "# for ad in soup.find_all(attrs={\"class\": lambda c: c and \"advertisement\" in c.lower()}):\n",
    "#     ad.decompose()\n",
    "# for ad in soup.find_all(id=lambda i: i and i.lower().startswith(\"ad_\")):\n",
    "#     ad.decompose()\n",
    "# # (The above are examples; you can adjust the filtering criteria based on the page's HTML structure.)\n",
    "\n",
    "# # 4. Use jusText to remove boilerplate and keep main textual content\n",
    "# paragraphs = justext.justext(str(soup), justext.get_stoplist(\"English\"))\n",
    "# clean_chunks = []\n",
    "# for para in paragraphs:\n",
    "#     if not para.is_boilerplate:  # not classified as boilerplate (navigation/menu/etc.)\n",
    "#         text = para.text.strip()\n",
    "#         if text:  # if non-empty\n",
    "#             clean_chunks.append(text)\n",
    "\n",
    "# # At this point, clean_chunks is a list of textual paragraphs in English that jusText considered content.\n",
    "\n",
    "# # 5. Output the cleaned content.\n",
    "# # Option A: Join as plain text paragraphs\n",
    "# clean_text = \"\\n\\n\".join(clean_chunks)\n",
    "# print(\"Cleaned Text Content:\\\\n\", clean_text)\n",
    "\n",
    "# # Option B: Reconstruct minimal HTML with basic structure (e.g., wrap each paragraph in <p> tags)\n",
    "# clean_html = \"<div>\\n\" + \"\\n\".join(f\"<p>{para}</p>\" for para in clean_chunks) + \"\\n</div>\"\n",
    "# print(\"Cleaned HTML Content:\\\\n\", clean_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 4 HTML pages into strings\n"
     ]
    }
   ],
   "source": [
    "from scrapper import HtmlScraper\n",
    "scraper = HtmlScraper(scraping_api_key=os.environ[\"SCRAPING_API_KEY\"])\n",
    "html_strings = scraper.load_saved_html()\n",
    "for i, html_string in enumerate(html_strings):\n",
    "    clean_text, clean_html = scraper.clean_html_content(html_string)\n",
    "    html_strings[i] = clean_html\n",
    "    # print(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for html_content in html_strings:\n",
    "    prompt = f\"\"\"\n",
    "You are given HTML webpage content. Extract the details precisely:\n",
    "\n",
    "- Business name, description, category, country of origin.\n",
    "- Each office location city and country.\n",
    "- Staff member details: name, position, email, phone, and social media accounts.\n",
    "\n",
    "Assume the PostgreSQL tables (`businesses`, `office_locations`, `staff`, `staff_social_media`) are already created with the following schema:\n",
    "\n",
    "{sql_schema}\n",
    "\n",
    "Do NOT include any CREATE TABLE commands. Assume `business_id` and `staff_id` are SERIAL PRIMARY KEYS, retrieved using RETURNING clauses in PostgreSQL.\n",
    "\n",
    "Provide exactly ONE executable PostgreSQL transaction (wrapped in BEGIN; ... COMMIT;) containing only valid INSERT commands, precisely formatted and ready to run through a Python script executing SQL commands. No additional explanations or formatting outside the SQL code.\n",
    "\n",
    "HTML Content:\n",
    "{html_content}\n",
    "\"\"\"\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from ollama_wrapper import ChatOllama\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load configuration\n",
    "def load_config(config_file=\"ollama_config.json\"):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    return config_data\n",
    "\n",
    "ollama_config_data = load_config()\n",
    "\n",
    "# Initialize the main LLM\n",
    "sql_generator = ChatOllama(\n",
    "    model=ollama_config_data[\"LLM\"],\n",
    "    base_url=ollama_config_data[\"BASE_URL\"],\n",
    "    temperature=ollama_config_data[\"TEMPERATURE\"],\n",
    ")\n",
    "\n",
    "# Define desired output schema as a Pydantic model\n",
    "class AnalysisResult(BaseModel):\n",
    "    sql_command: str\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = sql_generator.with_structured_output(AnalysisResult)\n",
    "\n",
    "# Lock to ensure proper synchronization when printing\n",
    "print_lock = threading.Lock()\n",
    "\n",
    "# Function to process and print each prompt\n",
    "def process_prompt(prompt):\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    with print_lock:\n",
    "        print(\"\\nPrompt:\")\n",
    "        print(\"=\"*80)\n",
    "        print(prompt)\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nGenerated SQL Command:\")\n",
    "        print(\"-\"*80)\n",
    "        print(result.sql_command)\n",
    "        print(\"-\"*80)\n",
    "\n",
    "# # Using threading to parallelly process prompts\n",
    "# threads = []\n",
    "# for prompt in prompts:\n",
    "#     thread = threading.Thread(target=process_prompt, args=(prompt,))\n",
    "#     threads.append(thread)\n",
    "#     thread.start()\n",
    "\n",
    "# # Wait for all threads to finish\n",
    "# for thread in threads:\n",
    "#     thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_or_service = \"Financial Consulting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are tasked with generating optimal candidate google search terms designed to maximize the retrieval of 'About Us' or 'Company Information' webpages specifically for businesses within a specified industry or service sector. \n",
      "\n",
      "Given the following target industry/service:\n",
      "\n",
      "\"Financial Consulting\"\n",
      "\n",
      "Produce a concise, highly relevant list of candidate search terms, each carefully tailored to improve the likelihood of retrieving accurate, informative business pages that typically contain company descriptions, histories, and key organizational information.\n",
      "\n",
      "The terms should be versatile enough to be used effectively in common web search engines like Google or Bing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are tasked with generating optimal candidate google search terms designed to maximize the retrieval of 'About Us' or 'Company Information' webpages specifically for businesses within a specified industry or service sector. \n",
    "\n",
    "Given the following target industry/service:\n",
    "\n",
    "\"{industry_or_service}\"\n",
    "\n",
    "Produce a concise, highly relevant list of candidate search terms, each carefully tailored to improve the likelihood of retrieving accurate, informative business pages that typically contain company descriptions, histories, and key organizational information.\n",
    "\n",
    "The terms should be versatile enough to be used effectively in common web search engines like Google or Bing.\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2229 column 1 (char 177859)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     28\u001b[39m structured_llm = sql_generator.with_structured_output(SearchTerms)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# # Lock to ensure proper synchronization when printing\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# print_lock = threading.Lock()\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# for thread in threads:\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m#     thread.join()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m result = \u001b[43mstructured_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPrompt:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/tech_projects/growbal/ollama_wrapper.py:232\u001b[39m, in \u001b[36mChatOllama.with_structured_output.<locals>.StructuredOutputRunnable.invoke\u001b[39m\u001b[34m(self, prompt_input)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# If parsing failed and raw output not requested, raise the error\u001b[39;00m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parsing_error:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m parsing_error\n\u001b[32m    233\u001b[39m     \u001b[38;5;66;03m# Return the parsed output directly (BaseModel instance or dict)\u001b[39;00m\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/tech_projects/growbal/ollama_wrapper.py:212\u001b[39m, in \u001b[36mChatOllama.with_structured_output.<locals>.StructuredOutputRunnable.invoke\u001b[39m\u001b[34m(self, prompt_input)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# If the schema is Pydantic, use model_validate to get an object\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.schema, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m.schema, BaseModel):\n\u001b[32m    209\u001b[39m         \u001b[38;5;66;03m# If content is a JSON string, ensure it's parsed to dict first\u001b[39;00m\n\u001b[32m    210\u001b[39m         \u001b[38;5;66;03m# If the content is already a JSON string from the model (it might include quotes if double-encoded),\u001b[39;00m\n\u001b[32m    211\u001b[39m         \u001b[38;5;66;03m# we attempt to load it.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_content\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_content, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m raw_content\n\u001b[32m    213\u001b[39m         parsed_output = \u001b[38;5;28mself\u001b[39m.schema.model_validate(data)  \u001b[38;5;66;03m# Pydantic v2 parsing\u001b[39;00m\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.schema, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    215\u001b[39m         \u001b[38;5;66;03m# If a direct JSON schema dict was provided, just parse the JSON string to dict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/growbal/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 2229 column 1 (char 177859)"
     ]
    }
   ],
   "source": [
    "# import threading\n",
    "# from ollama_wrapper import ChatOllama\n",
    "# import json\n",
    "# import os\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# # Load configuration\n",
    "# def load_config(config_file=\"ollama_config.json\"):\n",
    "#     with open(config_file, 'r') as f:\n",
    "#         config_data = json.load(f)\n",
    "#     return config_data\n",
    "\n",
    "# ollama_config_data = load_config()\n",
    "\n",
    "# # Initialize the main LLM\n",
    "# sql_generator = ChatOllama(\n",
    "#     model=ollama_config_data[\"LLM\"],\n",
    "#     base_url=ollama_config_data[\"BASE_URL\"],\n",
    "#     temperature=ollama_config_data[\"TEMPERATURE\"],\n",
    "# )\n",
    "\n",
    "# Define desired output schema as a Pydantic model\n",
    "class SearchTerms(BaseModel):\n",
    "    search_terms: list[str]\n",
    "    # search_terms: str\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = sql_generator.with_structured_output(SearchTerms)\n",
    "\n",
    "# # Lock to ensure proper synchronization when printing\n",
    "# print_lock = threading.Lock()\n",
    "\n",
    "# # Function to process and print each prompt\n",
    "# def process_prompt(prompt):\n",
    "#     result = structured_llm.invoke(prompt)\n",
    "#     with print_lock:\n",
    "#         print(\"\\nPrompt:\")\n",
    "#         print(\"=\"*80)\n",
    "#         print(prompt)\n",
    "#         print(\"=\"*80)\n",
    "#         print(\"\\nGenerated SQL Command:\")\n",
    "#         print(\"-\"*80)\n",
    "#         print(result.sql_command)\n",
    "#         print(\"-\"*80)\n",
    "\n",
    "# # Using threading to parallelly process prompts\n",
    "# threads = []\n",
    "# for prompt in prompts:\n",
    "#     thread = threading.Thread(target=process_prompt, args=(prompt,))\n",
    "#     threads.append(thread)\n",
    "#     thread.start()\n",
    "\n",
    "# # Wait for all threads to finish\n",
    "# for thread in threads:\n",
    "#     thread.join()\n",
    "\n",
    "result = structured_llm.invoke(prompt)\n",
    "print(\"\\nPrompt:\")\n",
    "print(\"=\"*80)\n",
    "print(prompt)\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated SQL Command:\")\n",
    "print(\"-\"*80)\n",
    "print(result.search_terms)\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from ollama_wrapper import ChatOllama\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load configuration\n",
    "def load_config(config_file=\"ollama_config.json\"):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    return config_data\n",
    "\n",
    "ollama_config_data = load_config()\n",
    "\n",
    "# Initialize the main LLM\n",
    "search_term_generator = ChatOllama(\n",
    "    model=ollama_config_data[\"LLM\"],\n",
    "    base_url=ollama_config_data[\"BASE_URL\"],\n",
    "    temperature=ollama_config_data[\"TEMPERATURE\"],\n",
    ")\n",
    "\n",
    "# Define desired output schema as a Pydantic model\n",
    "class SearchTermsResult(BaseModel):\n",
    "    search_terms: list[str]\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = search_term_generator.with_structured_output(SearchTermsResult)\n",
    "\n",
    "# Lock to ensure proper synchronization when printing\n",
    "print_lock = threading.Lock()\n",
    "\n",
    "# Function to process and print each prompt\n",
    "def process_prompt(prompt):\n",
    "    # prompt = f\"\"\"\n",
    "    # You are tasked with generating optimal candidate search terms designed to maximize the retrieval of 'About Us' or 'Company Information' webpages specifically for businesses within the following industry or service sector: \"{industry_or_service}\".\n",
    "\n",
    "    # Produce a concise, highly relevant list of candidate search terms, each carefully tailored to improve the likelihood of retrieving accurate, informative business pages that typically contain company descriptions, histories, and key organizational information.\n",
    "\n",
    "    # The terms should be versatile enough to be used effectively in common web search engines like Google or Bing.\n",
    "\n",
    "    # Respond with your output formatted as a JSON list.\n",
    "    # \"\"\"\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    with print_lock:\n",
    "        print(\"\\nPrompt:\")\n",
    "        print(\"=\"*80)\n",
    "        print(prompt)\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nGenerated Search Terms:\")\n",
    "        print(\"-\"*80)\n",
    "        print(result.search_terms)\n",
    "        print(\"-\"*80)\n",
    "\n",
    "# Example industries/services\n",
    "# industries_or_services = [\"Renewable Energy\", \"Legal Services\", \"Financial Consulting\"]\n",
    "# industries_or_services = [\"Financial Consulting\"]\n",
    "\n",
    "# # Using threading to parallelly process prompts\n",
    "# threads = []\n",
    "# for item in industries_or_services:\n",
    "#     thread = threading.Thread(target=process_prompt, args=(item,))\n",
    "#     threads.append(thread)\n",
    "#     thread.start()\n",
    "\n",
    "# # Wait for all threads to finish\n",
    "# for thread in threads:\n",
    "#     thread.join()\n",
    "\n",
    "# process_prompt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = structured_llm.invoke(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summaries(markdown_contents):\n",
    "    \"\"\"\n",
    "    Generates summaries for markdown content using GPT-4.\n",
    "    \n",
    "    Args:\n",
    "        markdown_contents: List of dictionaries containing markdown content and metadata\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing summaries and URLs\n",
    "    \"\"\"\n",
    "    # Create markdown_summaries directory if it doesn't exist\n",
    "    # pathlib.Path(\"markdown_summaries\").mkdir(exist_ok=True)\n",
    "\n",
    "    # Load the summary prompt\n",
    "    summary_prompt = load_prompt(\"summarise_markdown_page\")\n",
    "\n",
    "    # Create prompt template\n",
    "    summary_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", summary_prompt)\n",
    "    ])\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model)\n",
    "    summary_chain = summary_template | llm\n",
    "\n",
    "    # Generate and save summaries\n",
    "    summaries = []\n",
    "    for content in markdown_contents:\n",
    "        try:\n",
    "            # Generate summary, limiting to first 2000 words\n",
    "            summary = summary_chain.invoke({\n",
    "                'markdown_input': ' '.join(content['markdown'].split()[:3000])\n",
    "                # 'markdown_input': content['markdown']\n",
    "            })\n",
    "            \n",
    "            # Create filename for summary\n",
    "            # summary_filename = f\"summary_{content['id']}.md\"\n",
    "            # summary_filepath = os.path.join(\"markdown_summaries\", summary_filename)\n",
    "            \n",
    "            # Save summary to file\n",
    "            # with open(summary_filepath, 'w', encoding='utf-8') as f:\n",
    "            #     f.write(summary.content)\n",
    "            \n",
    "            # Add to summaries list\n",
    "            summaries.append({\n",
    "                'markdown_summary': summary.content,\n",
    "                'url': content['url']\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to summarize {content['url']}: {str(e)}\")\n",
    "\n",
    "    # print(f\"Successfully generated summaries for {len(markdown_contents)} pages in markdown_summaries/\")\n",
    "    print(f\"Successfully generated summaries for {len(markdown_contents)} pages\")\n",
    "    return summaries\n",
    "\n",
    "\n",
    "summaries = generate_summaries(markdown_contents)\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    summaries: List[dict]\n",
    "    approved: bool\n",
    "    created_summaries: Annotated[List[dict], Field(description=\"The summaries that have been created by the summariser\")]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Initialize components\n",
    "llm = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=llm_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load templates and prompts\n",
    "with open(\"email_template.md\", \"r\") as f:\n",
    "    email_template = f.read()\n",
    "\n",
    "class SummariserOutput(BaseModel):\n",
    "    email_summary: str = Field(description=\"The summary email of the content\")\n",
    "    message: str = Field(description=\"A message to the reviewer, asking for feedback on the summary\")\n",
    "\n",
    "summariser_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", load_prompt(\"summariser\")),\n",
    "    # (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "llm_summariser = summariser_prompt | llm.with_structured_output(SummariserOutput)\n",
    "\n",
    "def summariser(state: State):\n",
    "    converted_messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            converted_messages.append(HumanMessage(content=msg.content))\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            converted_messages.append(AIMessage(content=msg.content))\n",
    "        else:\n",
    "            converted_messages.append(msg)\n",
    "    state[\"messages\"] = converted_messages\n",
    "    summariser_output = llm_summariser.invoke({\"messages\": state[\"messages\"], \"list_of_summaries\": state[\"summaries\"], \"input_template\": email_template})\n",
    "    new_messages = [AIMessage(content=summariser_output.email_summary), AIMessage(content=summariser_output.message)]\n",
    "    return {\"messages\": new_messages, \"created_summaries\": [summariser_output.email_summary]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ReviewerOutput(BaseModel):\n",
    "    approved: bool = Field(description=\"Whether the summary is approved or not\")\n",
    "    message: str = Field(description=\"A message to the reviewer, asking for feedback on the summary\")\n",
    "\n",
    "reviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", load_prompt(\"reviewer\")),\n",
    "    # (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "\n",
    "llm_reviewer = reviewer_prompt | llm.with_structured_output(ReviewerOutput)\n",
    "\n",
    "\n",
    "def reviewer(state: State):\n",
    "    # Convert AIMessages to HumanMessages and vice versa\n",
    "    converted_messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            converted_messages.append(HumanMessage(content=msg.content))\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            converted_messages.append(AIMessage(content=msg.content))\n",
    "        else:\n",
    "            converted_messages.append(msg)\n",
    "    state[\"messages\"] = converted_messages\n",
    "    reviewer_output = llm_reviewer.invoke({\"messages\": state[\"messages\"]})\n",
    "    new_messages = [AIMessage(content=reviewer_output.message)]\n",
    "    return {\"messages\": new_messages, \"approved\": reviewer_output.approved}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conditional_edge(state: State) -> Literal[\"summariser\", END]:\n",
    "    if state[\"approved\"]:\n",
    "        return END\n",
    "    else:\n",
    "        return \"summariser\"\n",
    "\n",
    "\n",
    "# Create and configure the graph\n",
    "graph_builder.add_node(\"summariser\", summariser)\n",
    "graph_builder.add_node(\"reviewer\", reviewer)\n",
    "graph_builder.add_edge(START, \"summariser\")\n",
    "graph_builder.add_edge(\"summariser\", \"reviewer\")\n",
    "graph_builder.add_conditional_edges('reviewer', conditional_edge)\n",
    "\n",
    "# Compile and run the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "output = graph.invoke({\"summaries\": summaries})\n",
    "\n",
    "\n",
    "\n",
    "def send_email(email_content: str):\n",
    "    configuration = sib_api_v3_sdk.Configuration()\n",
    "    \n",
    "    api_key = os.getenv(\"SENDINGBLUE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"SENDINGBLUE_API_KEY environment variable not set.\")\n",
    "    \n",
    "    configuration.api_key['api-key'] = api_key\n",
    "    \n",
    "    sender_email = os.getenv(\"SENDER_EMAIL\")\n",
    "    recipient_email = os.getenv(\"DESTINATION_EMAIL\")\n",
    "    \n",
    "    if not sender_email or not recipient_email:\n",
    "        raise ValueError(\"Sender or Destination email environment variable not set.\")\n",
    "\n",
    "    api_instance = sib_api_v3_sdk.TransactionalEmailsApi(sib_api_v3_sdk.ApiClient(configuration))\n",
    "\n",
    "    email_params = {\n",
    "        \"subject\": \"Daily Summary\",\n",
    "        \"sender\": {\"name\": \"Mohammed Elsiddig\", \"email\": sender_email},\n",
    "        \"html_content\": email_content,\n",
    "        \"to\": [{\"email\": recipient_email, \"name\": \"Mohammed Elsiddig\"}],\n",
    "        \"params\": {\"subject\": \"Daily Summary\"}\n",
    "    }\n",
    "\n",
    "    send_smtp_email = sib_api_v3_sdk.SendSmtpEmail(**email_params)\n",
    "\n",
    "    try:\n",
    "        api_response = api_instance.send_transac_email(send_smtp_email)\n",
    "        print(api_response)\n",
    "    except ApiException as e:\n",
    "        print(f\"Exception: {e}\\n\")\n",
    "\n",
    "send_email(final_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growbal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
