{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b09f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Literal, TypedDict, List, Dict, Any\n",
    "from typing_extensions import NotRequired\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('/home/mohammed/Desktop/tech_projects/growbal/envs/1.env')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "serp_api_key = os.getenv('SERPER_API_KEY')\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "# Removed SQLite checkpointing for now\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.utilities import SerpAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres import PGVector  # or use FAISS if local\n",
    "# pip: langgraph, langgraph-checkpoint-sqlite, langchain-openai, langchain-community, langchain-postgres\n",
    "\n",
    "# ---------- State ----------\n",
    "class ChecklistItem(TypedDict):\n",
    "    key: str\n",
    "    prompt: str\n",
    "    required: bool\n",
    "    status: Literal[\"PENDING\",\"ASKED\",\"ANSWERED\",\"VERIFIED\",\"BLOCKED\"]\n",
    "    value: NotRequired[str]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    provider_profile: Dict[str, Any]\n",
    "    checklist: List[ChecklistItem]\n",
    "    research_notes: List[Dict[str, Any]]\n",
    "    vector_store_id: NotRequired[str]\n",
    "    status: Literal[\"ON_TRACK\",\"NEEDS_INFO\",\"ESCALATE\",\"FINALIZE_SAVE\",\"RESTART\",\"ABORT\"]\n",
    "\n",
    "# ---------- Models & Tools ----------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=openai_api_key).bind_tools([])  # we bind later if desired\n",
    "serp = SerpAPIWrapper(serpapi_api_key=serp_api_key)  # Initialize with API key\n",
    "arxiv = ArxivAPIWrapper()\n",
    "# Wikipedia -> use loader since summaries come as Documents\n",
    "def wiki_search(query: str, k=3):\n",
    "    return WikipediaLoader(query=query, load_max_docs=k).load()\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web using SERP API.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to run\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a string\n",
    "    \"\"\"\n",
    "    return serp.run(query)\n",
    "\n",
    "def search_arxiv(query: str) -> str:\n",
    "    \"\"\"Search academic papers on ArXiv.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for ArXiv\n",
    "        \n",
    "    Returns:\n",
    "        Relevant paper information as a string\n",
    "    \"\"\"\n",
    "    return arxiv.run(query)\n",
    "\n",
    "def search_wikipedia(query: str) -> List[str]:\n",
    "    \"\"\"Search Wikipedia articles.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for Wikipedia\n",
    "        \n",
    "    Returns:\n",
    "        List of relevant Wikipedia article contents\n",
    "    \"\"\"\n",
    "    return [d.page_content for d in wiki_search(query)]\n",
    "\n",
    "tools = {\n",
    "    \"serp\": search_web,\n",
    "    \"arxiv\": search_arxiv,\n",
    "    \"wikipedia\": search_wikipedia\n",
    "}\n",
    "\n",
    "tool_node = ToolNode(tools=list(tools.values()))  # Pass the functions as a list\n",
    "\n",
    "# ---------- Nodes ----------\n",
    "def intake_and_clarify(state: State):\n",
    "    \"\"\"Generate crisp, minimal clarifying Qs based on provider_profile + checklist PENDING items.\"\"\"\n",
    "    # produce 1-3 high-signal questions, store as messages & mark items ASKED\n",
    "    # (omitted: prompt; keep deterministic)\n",
    "    return {\"messages\": [{\"role\":\"assistant\",\"content\":\"...clarifying Qs...\"}]}\n",
    "\n",
    "def research_planner(state: State):\n",
    "    \"\"\"Decide which tools to call for which queries.\"\"\"\n",
    "    queries = []  # craft from checklist gaps + provider niche\n",
    "    # Return messages with tool-calls as per LangGraph ToolNode contract (AIMessage w/ tool calls)\n",
    "    return {\"messages\":[{\"role\":\"assistant\",\"tool_calls\":[{\"id\":\"t1\",\"name\":\"serp\",\"args\":{\"q\": \"best practices for UAE tax\"}}, ...]}]}\n",
    "\n",
    "def parse_and_index(state: State):\n",
    "    \"\"\"Chunk, embed, and upsert documents; store collection handle.\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=150)\n",
    "    texts = state.get(\"research_notes\", [])\n",
    "    chunks = [c for t in texts for c in splitter.split_text(t[\"content\"])]\n",
    "    if chunks:\n",
    "        vs = PGVector.from_texts(\n",
    "            texts=chunks,\n",
    "            embedding=OpenAIEmbeddings(),  # swap for Voyage/Cohere/etc.\n",
    "            collection_name=\"provider_\"+state[\"provider_profile\"][\"id\"]\n",
    "        )\n",
    "        return {\"vector_store_id\": vs.collection_name}\n",
    "    return {}\n",
    "\n",
    "def summarize_and_update_checklist(state: State):\n",
    "    \"\"\"Pull top-k from vector store and produce concise answers; update checklist values/status.\"\"\"\n",
    "    # pseudo: docs = vs.as_retriever(k=6).invoke(question)\n",
    "    # update checklist items -> ANSWERED/VERIFIED as appropriate\n",
    "    updated = []\n",
    "    for item in state[\"checklist\"]:\n",
    "        if item[\"status\"] in (\"PENDING\",\"ASKED\"):\n",
    "            # ...set value/status deterministically based on retrieved evidence...\n",
    "            item = {**item, \"status\":\"ANSWERED\"}\n",
    "        updated.append(item)\n",
    "    return {\"checklist\": updated, \"messages\":[{\"role\":\"assistant\",\"content\":\"Drafted answers & notes.\"}]}\n",
    "\n",
    "def status_router(state: State):\n",
    "    cl = state[\"checklist\"]\n",
    "    if any(i[\"required\"] and i[\"status\"] in (\"PENDING\",\"ASKED\") for i in cl):\n",
    "        return \"AskMore\"\n",
    "    if all((not i[\"required\"]) or i[\"status\"] in (\"ANSWERED\",\"VERIFIED\") for i in cl):\n",
    "        return \"SaveAndClose\"\n",
    "    # detect conflicts / tool failures (omitted): route to ESCALATE if needed\n",
    "    return \"ResearchPlanner\"  # keep looping until done\n",
    "\n",
    "def ask_more(state: State):\n",
    "    \"\"\"Ask only the missing high-signal items, not a form dump.\"\"\"\n",
    "    return {\"messages\":[{\"role\":\"assistant\",\"content\":\"I still need just these 2 details: ...\"}], \"status\":\"NEEDS_INFO\"}\n",
    "\n",
    "def save_and_close(state: State):\n",
    "    \"\"\"Persist provider summary & request supporting documents.\"\"\"\n",
    "    return {\n",
    "        \"status\":\"FINALIZE_SAVE\",\n",
    "        \"messages\":[{\"role\":\"assistant\",\"content\":\"Saved your profile. Upload any supporting documents now (optional).\"}]\n",
    "    }\n",
    "\n",
    "# ---------- Graph ----------\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"IntakeAndClarify\", intake_and_clarify)\n",
    "graph.add_node(\"ResearchPlanner\", research_planner)\n",
    "graph.add_node(\"ToolExec\", tool_node)  # executes serp/wiki/arxiv concurrently\n",
    "graph.add_node(\"ParseAndIndex\", parse_and_index)\n",
    "graph.add_node(\"SummarizeAndUpdate\", summarize_and_update_checklist)\n",
    "graph.add_node(\"AskMore\", ask_more)\n",
    "graph.add_node(\"SaveAndClose\", save_and_close)\n",
    "\n",
    "graph.add_edge(START, \"IntakeAndClarify\")\n",
    "graph.add_edge(\"IntakeAndClarify\", \"ResearchPlanner\")\n",
    "graph.add_edge(\"ResearchPlanner\", \"ToolExec\")\n",
    "graph.add_edge(\"ToolExec\", \"ParseAndIndex\")\n",
    "graph.add_edge(\"ParseAndIndex\", \"SummarizeAndUpdate\")\n",
    "graph.add_conditional_edges(\"SummarizeAndUpdate\", status_router, {\n",
    "    \"AskMore\": \"AskMore\",\n",
    "    \"SaveAndClose\": \"SaveAndClose\",\n",
    "    \"ResearchPlanner\": \"ResearchPlanner\",\n",
    "})\n",
    "graph.add_edge(\"AskMore\", \"ResearchPlanner\")\n",
    "graph.add_edge(\"SaveAndClose\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "# invoke with: app.invoke({\"messages\": [], \"provider_profile\": {}, \"checklist\": [], \"research_notes\": []})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the workflow graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Ensure pygraphviz is available in this kernel\n",
    "try:\n",
    "    import pygraphviz  # noqa: F401\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pygraphviz\"])  # quiet install\n",
    "        import pygraphviz  # noqa: F401\n",
    "    except Exception as install_e:\n",
    "        print(\"pygraphviz install failed:\", install_e)\n",
    "\n",
    "# Render the compiled graph (or the uncompiled graph as fallback)\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    try:\n",
    "        display(Image(graph.get_graph().draw_png()))\n",
    "    except Exception as inner_e:\n",
    "        print(\"Graph visualization failed:\", e or inner_e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onboarding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
